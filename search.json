[
  {
    "objectID": "2019_euads/MD/S4.html",
    "href": "2019_euads/MD/S4.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Data Science is for, about, by and with humans.\n\n\nFAT Forensics"
  },
  {
    "objectID": "2019_euads/MD/S4.html#the-human-factor",
    "href": "2019_euads/MD/S4.html#the-human-factor",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Data Science is for, about, by and with humans.\n\n\nFAT Forensics"
  },
  {
    "objectID": "2019_euads/MD/S5.html",
    "href": "2019_euads/MD/S5.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "highly multi-disciplinary -&gt; provide bridges between disciplines\nmany stakeholders, need to balance interests of all\ninformation about resources, best practice etc. is highly scattered\ntraining programmes\nconferences & events\norganisations\nfunding opportunities\nlegal & ethical framework\ntech infrastructure\n\n\n\n\nEuropean diversity -&gt; data can be an integrative force\nData to guide major European projects, e.g. in o Environmental preservation o Socio-economic development o Fostering equality and diversity\nImplications and challenges • Efforts towards a more data driven European development need to be pooled and coordinated on different levels: o Research and science o Politics o Communication • Data within the public sector needs to be accessible and documented (Data Management) • Finding the right communication channels and form to make data-based/informed communication accessible to the public.\nWhat contributions can EuADS provide? • Contribution to the political process from a (data) scientific perspective • Networking of players in the field of data science. Among one another and with politicians. • Setting a European focus within the data science community."
  },
  {
    "objectID": "2019_euads/MD/S5.html#about-euads",
    "href": "2019_euads/MD/S5.html#about-euads",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "highly multi-disciplinary -&gt; provide bridges between disciplines\nmany stakeholders, need to balance interests of all\ninformation about resources, best practice etc. is highly scattered\ntraining programmes\nconferences & events\norganisations\nfunding opportunities\nlegal & ethical framework\ntech infrastructure\n\n\n\n\nEuropean diversity -&gt; data can be an integrative force\nData to guide major European projects, e.g. in o Environmental preservation o Socio-economic development o Fostering equality and diversity\nImplications and challenges • Efforts towards a more data driven European development need to be pooled and coordinated on different levels: o Research and science o Politics o Communication • Data within the public sector needs to be accessible and documented (Data Management) • Finding the right communication channels and form to make data-based/informed communication accessible to the public.\nWhat contributions can EuADS provide? • Contribution to the political process from a (data) scientific perspective • Networking of players in the field of data science. Among one another and with politicians. • Setting a European focus within the data science community."
  },
  {
    "objectID": "2019_euads/MD/MD.html",
    "href": "2019_euads/MD/MD.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "The Science of Data?\n\n\nmachine learning & statistics research\n\n\nDoing Science with Data?\n\n\ndata-intensive research\n\n\nApplying Science to Data?\n\n\ndata-intensive \\(X\\)\n\n\n\n\nData can broadly be described as factual information about events, situations, circumstances etc. in the world around us.\nData is often hailed as the “new oil” or the “new electricity”, to highlight its transformative potential as a driver of prosperity in the twenty-first century.\n\n\n\nHowever, the absence of a fixed physical form as well as data’s often transient nature imply that\nthe potential for and challenges of collecting, processing, and exploiting data are incomparable with physical resources.\n\n\n\nWhile data is a vehicle for describing the world around us, knowledge is the carrier of understanding: - (K in) Domain knowledge is indispensable for understanding the meaning of data and for processing and exploiting it in a productive way. - (K out) Further knowledge is produced by applying analytics to data.\n\n\n\nData Science is a family of disciplines operating at the junction of data and knowledge, building on rich data and domain knowledge to produce value in a variety of forms.\nThese disciplines range from methodological subjects (statistics, machine learning, data mining) to data-driven applications in other domains (psychology, social science, economics, history, among many others).\n\n\n\n\nscientific knowledge and models\nsocietal value\neconomic value\npersonal value\n…"
  },
  {
    "objectID": "2019_euads/MD/MD.html#what-is-data-science-15",
    "href": "2019_euads/MD/MD.html#what-is-data-science-15",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "The Science of Data?\n\n\nmachine learning & statistics research\n\n\nDoing Science with Data?\n\n\ndata-intensive research\n\n\nApplying Science to Data?\n\n\ndata-intensive \\(X\\)\n\n\n\n\nData can broadly be described as factual information about events, situations, circumstances etc. in the world around us.\nData is often hailed as the “new oil” or the “new electricity”, to highlight its transformative potential as a driver of prosperity in the twenty-first century.\n\n\n\nHowever, the absence of a fixed physical form as well as data’s often transient nature imply that\nthe potential for and challenges of collecting, processing, and exploiting data are incomparable with physical resources.\n\n\n\nWhile data is a vehicle for describing the world around us, knowledge is the carrier of understanding: - (K in) Domain knowledge is indispensable for understanding the meaning of data and for processing and exploiting it in a productive way. - (K out) Further knowledge is produced by applying analytics to data.\n\n\n\nData Science is a family of disciplines operating at the junction of data and knowledge, building on rich data and domain knowledge to produce value in a variety of forms.\nThese disciplines range from methodological subjects (statistics, machine learning, data mining) to data-driven applications in other domains (psychology, social science, economics, history, among many others).\n\n\n\n\nscientific knowledge and models\nsocietal value\neconomic value\npersonal value\n…"
  },
  {
    "objectID": "2019_euads/MD/MD.html#from-data-mining-to-data-science-25",
    "href": "2019_euads/MD/MD.html#from-data-mining-to-data-science-25",
    "title": "Peter Flach Slides",
    "section": "From Data Mining to Data Science (2/5)",
    "text": "From Data Mining to Data Science (2/5)\n\n \n\n\nCRISP-DM (1999)\n\n \n\n\n\nCRISP-DM evolution\n\n \n\nAdapted from G. Mariscal, O. Marban, and C. Fernandez: A survey of datamining and knowledge discovery process models and methodologies, Knowledge Engineering Review 25(2):137-166, 2010.\n\n\nData takes centre stage\nContemporary Data Science starts from the data: - We know or suspect there is value in these data, how do we unlock it? - What are the possible operations we can apply to the data to unlock and utilise their value?\nWhile moving away from the process the methodology becomes less prescriptive and more inquisitive: things you can do to data rather than things you should do to data.\n\n\nFrom mining to prospecting\nIf data mining is like mining for precious metals, Data Science is like prospecting: searching for deposits of precious metals where profitable mines can be located.\nSuch a prospecting process is fundamentally exploratory and can include some of the following activities:\n\n\nExploratory activities in Data Science\n\nGoal exploration: finding business goals which can be achieved in a data-driven way;\nData source exploration: discovering new and valuable sources of data;\nData value exploration: finding out what value might be extracted from given data;\nResult exploration: relating Data Science results back to the business goals;\nNarrative exploration: extracting valuable stories (e.g., visual or textual) from the data;\nProduct exploration: finding ways to turn the value extracted from the data into a service or app.\n\n\n\nDST space\n\n \n\n\n\nTravelling through DST space\n\n \n\n\n\nA Data Science Trajectory\n\n \n\n\nGoal Exploration: activity recommender for tourists\nData Value Exploration: get third-party location data\nData Preparation: create user-location-activity ratings\nModelling: train a recommender system\nProduct Exploration: explore most appropriate end-user product/presentation\n\n\n\nLooping\n\n \n\n\n\nNot all trajectories require Modelling\n\n     \n\n\n\nWatch this space!\nCRISP-DM Twenty Years Later: From Data Mining Processes to Data Science Trajectories. Fernando Martinez-Plumed, Lidia Contreras-Ochando, Cesar Ferri, Jose Hernandez-Orallo, Meelis Kull, Nicolas Lachiche, Maria Jose Ramirez-Quintana and Peter Flach. (Under review, 2019)"
  },
  {
    "objectID": "2019_euads/MD/MD.html#the-human-factor-35",
    "href": "2019_euads/MD/MD.html#the-human-factor-35",
    "title": "Peter Flach Slides",
    "section": "The Human Factor (3/5)",
    "text": "The Human Factor (3/5)\nData Science is for, about, by and with humans.\nResponsible Data Science means taking the human factor into account at all stages.\n\nHere I offer a few personal thoughts, also inspired by parallel discussions and developments in Human-Centred AI.\n\n\nFairness, Accountability and Transparency\nThese are important aspects contributing to Responsible Data Science.\n\nBut aspirations are not enough, and much more work is needed to work out - how to define them? - how to measure them? - how to achieve them?\n\n\n\nFair or not?\n\n\n\nMen applied\nMen admitted\n%\nWomen applied\nWomen admitted\n%\n\n\n\n\n\n2691\n1198\n45%\n1835\n557\n30%\n\n\n\nA\n825\n512\n62%\n108\n89\n82%\n\n\nB\n560\n353\n63%\n25\n17\n68%\n\n\nC\n325\n120\n37%\n593\n202\n34%\n\n\nD\n417\n138\n33%\n375\n131\n35%\n\n\nE\n191\n53\n28%\n393\n94\n24%\n\n\nF\n373\n22\n6%\n341\n24\n7%\n\n\n\n\n\nHumans in the Loop\nThere is a clear need to model the entire Data Science ecosystem, including human actors in their various roles.\nThis will allow keeping track of artefacts as they are created and travel through the ecosystem (provenance).\nUltimately such a model needs to be causal so that we can reason about the consequences of (not) doing something.\n\n\nCaveats\nCampbell’s Law: “The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.”\nGoodhart’s Law: “When a measure becomes a target, it ceases to be a good measure.”\n\n\nData for All?\nIf Data has intrinsic value, we need to consider - data ownership; - who profits from the additional value created.\n\nCurrently, users often give their data away freely in exchange for a service. Is this sustainable?\n\n\n\nGDPR\nMore control for individuals over their personal data: - the need for the individual’s clear consent to the processing of personal data; - easier access by the subject to his or her personal data; - the rights to rectification, to erasure and ‘to be forgotten’; - the right to object, including to the use of personal data for the purposes of ‘profiling’; - the right to data portability from one service provider to another.\n\n\nConsent\nFor consent to be valid it must be informed consent. For this to be the case it must be: - given voluntarily (with no coercion or deceit); - given by an individual who has capacity; - given by an individual who has been fully informed about the issue.\n\nIs consent informed if it is hidden in many pages of dense legalese?\n\n\n\nEthics to the rescue?\nIt is important to discuss and reach consensus on ethical issues raised by Data Science.\n\nIt is equally important to realise that -  ethics existed long before Data Science & AI came to the fore; -  ethics is not prescriptive and may need to be followed by regulation and legislation to become effective."
  },
  {
    "objectID": "2019_euads/MD/MD.html#about-euads-45",
    "href": "2019_euads/MD/MD.html#about-euads-45",
    "title": "Peter Flach Slides",
    "section": "About EuADS (4/5)",
    "text": "About EuADS (4/5)\nIn such a multi-disciplinary and varied landscape it is important to provide bridges between disciplines and balance the interests of stakeholders.\nTo support this, EuADS aims to bring together information about resources, best practice etc.: - training programmes - conferences, events & organisations - funding opportunities & job openings - technology infrastructure - legal & ethical frameworks\n\nEuADS activities so far\n\nCo-organised the European Conferences on Data Analysis (ECDA)\n\nLuxembourg 2013, Bremen 2014, Colchester 2015, Wroclaw 2017, Paderborn 2018, Bayreuth 2019\n\nOrganised the European Data Science Conference (Luxembourg, Nov. 2016).\nGuest-edited a special issue on Data Science in Europe of the Int. J. of Data Science and Analytics (2018).\nOrganised the first European Summer School on Explainable Data Science (Luxembourg, Sept. 2019).\n\n\n\nEDSC 2016\nThe EDSC programme consisted of invited plenary talks, symposia, workshops and panel discussions on: - The question of trust, transparency and provenance. - Legal aspects of Data Science such as data protection, data privacy and data access. - Support for navigating the complex chain from raw data to actionable outputs . - The role of Data Science in medicine and health care . - How to define the field’s methodological substance.\nSee Int.J. Data Science and Analytics 6(3), 2018.\n\n\nExplainable Data Science Summer School\n\nHuman-centric data exploration: Tijl De Bie (U Gent, B)\nExplanations from a psychological perspective: Christos Bechlivanidis (University College London, UK)\nXAI - Science and technology for the explanation of AI decision making: Fosca Giannotti (Information Science and Technology Institute Pisa, I)\nMaking Data Science Intelligible: Simone Stumpf (City, U of London, UK)\nCausal inference from empirical data: Jilles Vreeken (CISPA Helmholtz Center for Information Security, D)\n\n\n\nTwo-way platforms\n\nData Science jobs\nData Science experts\nData Science projects\nData Science education\nData marketplace\nData Science for Europe\n\n\n\nThe European dimension\nData can be an integrative force to handle, and benefit from, European diversity.\nData can guide major European projects (e.g., environmental, socio-economic, equality & diversity).\nEfforts towards a more data-driven European development need to be pooled and coordinated on different levels (e.g., science & technology, politics, public engagement).\n\n\nHow can you get involved?\n\nBecome a EuADS member.\nGet your organisation to become an institutional member.\nBecome a national representative.\nHelp organise events such as this one.\nHelp build our two-way platforms.\n…\n\nNavigate to EuADS.org.\n\n\nSabine Krolak-Schwerdt, 1958-2017"
  },
  {
    "objectID": "2019_euads/MD/MD.html#recap-55",
    "href": "2019_euads/MD/MD.html#recap-55",
    "title": "Peter Flach Slides",
    "section": "Recap (5/5)",
    "text": "Recap (5/5)\n\n\nWhether seen as the science of data, doing science with data, or applying science to data: data science is inherently multi-disciplinary and requires sustained interaction between disciplines.\n\nTracing its evolution from data mining exposes the essentially exploratory nature of data science.\n\nThe human factor raises important questions, e.g. regarding ownership of data and results, and where regulation/legislation is needed.\n\nThe EuADS mission is to help articulate, support and advance these challenges and opportunities."
  },
  {
    "objectID": "2019_euads/MD/S6.html",
    "href": "2019_euads/MD/S6.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Sabine Krolak-Schwerdt, 1958-2017"
  },
  {
    "objectID": "2019_euads/MD/S1.html",
    "href": "2019_euads/MD/S1.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "The Science of Data?\n\nmachine learning & statistics research\n\nDoing Science with Data?\n\ndata-intensive research\n\nApplying Science to Data?\n\ndata-intensive X\n\n\n\n\nData can broadly be described as factual information about events, situations, circumstances etc. in the world around us.\nData is often hailed as the “new oil” or the “new electricity”, to highlight its transformative potential as a driver of prosperity in the twenty-first century.\n\n\n\nHowever, the absence of a fixed physical form as well as its often transient nature imply that the potential for and challenges of collecting, processing, and exploiting data are incomparable with physical resources.\n\n\n\nWhile data is a vehicle for describing the world around us, knowledge is the carrier of understanding: - (K in) Domain knowledge is indispensable for understanding the meaning of data and for processing and exploiting it in a productive way. - (K out) Further knowledge is produced by applying analytics to data.\n\n\n\nData science is a family of disciplines operating at the junction of data and knowledge, building on rich data and domain knowledge to produce value in a variety of forms.\nThese disciplines range from methodological subjects (statistics, machine learning, data mining) to data-driven applications in other domains (psychology, social science, economics, history, among many others).\n\n\n\n\nscientific knowledge and models\nsocietal value\neconomic value\npersonal value\n…"
  },
  {
    "objectID": "2019_euads/MD/S1.html#what-is-data-science",
    "href": "2019_euads/MD/S1.html#what-is-data-science",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "The Science of Data?\n\nmachine learning & statistics research\n\nDoing Science with Data?\n\ndata-intensive research\n\nApplying Science to Data?\n\ndata-intensive X\n\n\n\n\nData can broadly be described as factual information about events, situations, circumstances etc. in the world around us.\nData is often hailed as the “new oil” or the “new electricity”, to highlight its transformative potential as a driver of prosperity in the twenty-first century.\n\n\n\nHowever, the absence of a fixed physical form as well as its often transient nature imply that the potential for and challenges of collecting, processing, and exploiting data are incomparable with physical resources.\n\n\n\nWhile data is a vehicle for describing the world around us, knowledge is the carrier of understanding: - (K in) Domain knowledge is indispensable for understanding the meaning of data and for processing and exploiting it in a productive way. - (K out) Further knowledge is produced by applying analytics to data.\n\n\n\nData science is a family of disciplines operating at the junction of data and knowledge, building on rich data and domain knowledge to produce value in a variety of forms.\nThese disciplines range from methodological subjects (statistics, machine learning, data mining) to data-driven applications in other domains (psychology, social science, economics, history, among many others).\n\n\n\n\nscientific knowledge and models\nsocietal value\neconomic value\npersonal value\n…"
  },
  {
    "objectID": "2019_euads/MD/template.html",
    "href": "2019_euads/MD/template.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Slide 1 - italics - sublist - boldface\n\n\nSlide 2\n\n\n\nSlide 3"
  },
  {
    "objectID": "2019_euads/MD/template.html#section-title",
    "href": "2019_euads/MD/template.html#section-title",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Slide 1 - italics - sublist - boldface\n\n\nSlide 2\n\n\n\nSlide 3"
  },
  {
    "objectID": "2019_euads/MD/S2.html",
    "href": "2019_euads/MD/S2.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Adapted from G. Mariscal, O. Marban, and C. Fernandez: A survey of datamining and knowledge discovery process models and methodologies, Knowledge Engineering Review 25(2):137-166, 2010.\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\nGoal Exploration: location/activity recommender for tourists\nData Value Exploration: retrieve third-party location data\nData Preparation: create user-location-activity rating tensor\nModelling: train a recommender system\nProduct Exploration: explore most appropriate end-user product/presentation"
  },
  {
    "objectID": "2019_euads/MD/S2.html#from-data-mining-to-data-science",
    "href": "2019_euads/MD/S2.html#from-data-mining-to-data-science",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Adapted from G. Mariscal, O. Marban, and C. Fernandez: A survey of datamining and knowledge discovery process models and methodologies, Knowledge Engineering Review 25(2):137-166, 2010.\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n \n\n\nGoal Exploration: location/activity recommender for tourists\nData Value Exploration: retrieve third-party location data\nData Preparation: create user-location-activity rating tensor\nModelling: train a recommender system\nProduct Exploration: explore most appropriate end-user product/presentation"
  },
  {
    "objectID": "2021_nightingale/MD/All.html",
    "href": "2021_nightingale/MD/All.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is (a) very unlikely, and (b) not under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for a given trade-off between precision and recall.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#why-should-you-care-about-measurement",
    "href": "2021_nightingale/MD/All.html#why-should-you-care-about-measurement",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is (a) very unlikely, and (b) not under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for a given trade-off between precision and recall.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#scales-units-dimensions-and-types",
    "href": "2021_nightingale/MD/All.html#scales-units-dimensions-and-types",
    "title": "Peter Flach Slides",
    "section": "Scales, units, dimensions and types",
    "text": "Scales, units, dimensions and types\nPerhaps surprisingly, there doesn’t seem to be a definitive framework to link all these concepts together.\nWe’ll look at it from a few perspectives:\n\nLevels of measurement\nThe physics perspective\nThe computer science perspective"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#levels-of-measurement",
    "href": "2021_nightingale/MD/All.html#levels-of-measurement",
    "title": "Peter Flach Slides",
    "section": "Levels of measurement",
    "text": "Levels of measurement\n   \nEarly proposal from a psychologist (Stevens, 1946), still influential although somewhat rigid and limited.\n\nStevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”.\n\n\nAdmissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above.\n\n\nLevels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning! \n\n\nAlternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2021_nightingale/MD/All.html#the-physics-perspective",
    "href": "2021_nightingale/MD/All.html#the-physics-perspective",
    "title": "Peter Flach Slides",
    "section": "The physics perspective",
    "text": "The physics perspective\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added or subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\n\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\nDimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\).\n\n\n\n\nHow to build on this in data science and AI?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#the-computer-science-perspective",
    "href": "2021_nightingale/MD/All.html#the-computer-science-perspective",
    "title": "Peter Flach Slides",
    "section": "The computer science perspective",
    "text": "The computer science perspective\n\nAbstract data types are more flexible than dimensions or scale types as they can be adapted to the situation of interest.\n\nprovide relevant meta-data about measurements\nlink to useful operations.\n\nIn particular, higher-order functional languages such as Haskell allow reasoning with and about types.\n\nThis provides a formal language and logic for measurement meta-data.\n\nThe challenge is to develop a generally agreed “Systeme international” of ML measurements.\n\n\nExample: Shannon entropy\n \n\n\nExample: Scoring rules"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#you-cant-always-measure-what-you-want",
    "href": "2021_nightingale/MD/All.html#you-cant-always-measure-what-you-want",
    "title": "Peter Flach Slides",
    "section": "You can’t always measure what you want…",
    "text": "You can’t always measure what you want…\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those latent variable models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\nIRT from a machine learning perspective\n\n\n\nIRT\n\n\n\n\\(\\theta_i\\): ability of participant \\(i\\)\n\\(\\delta_j\\), \\(a_j\\): difficulty & discrimination of item \\(j\\)\n\\(x_{ij}\\): binary response (correct/incorrect)\n\n\n\nBeta-IRT\n\n\n\nBeta-IRT\n\n\n\ncontinuous responses \\(p_{ij}\\)\nabilities & difficulties \\(\\in [0,1]\\)\n\n\n\nBeta-IRT: flexible Item Characteristic Curves\n\n\n\nBeta-IRT ICC\n\n\n\ndiscrimination \\(a_j\\) can be negative, indicating an item that confuses high-ability participants! \n\n\n\nIdea 1: Identifying noisy examples\n \n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\n\n\n\nIdea 2: Adaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\n\n\nCAT results\n \n\nSong, H. and Flach, P., 2020. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Int J Interactive Multimedia and AI 2021."
  },
  {
    "objectID": "2021_nightingale/MD/All.html#outlook",
    "href": "2021_nightingale/MD/All.html#outlook",
    "title": "Peter Flach Slides",
    "section": "Outlook",
    "text": "Outlook\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., if the classes were re-balanced (counterfactual intervention) the difference in performance would disappear. \n\nNB. In empirical ML we can actually carry out interventions, which makes causal inference a whole lot easier!"
  },
  {
    "objectID": "2021_nightingale/MD/All.html#concluding-remarks",
    "href": "2021_nightingale/MD/All.html#concluding-remarks",
    "title": "Peter Flach Slides",
    "section": "Concluding remarks",
    "text": "Concluding remarks\nProper treatment of performance evaluation in data science and AI requires a sophisticated measurement framework with the following components: - Coherent types and meta-data for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute; papers, code and videos can be accessed here.\nMany thanks to Hao Song, the Research Associate on the project; and collaborators Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Raul Santos-Rodriguez and many others."
  },
  {
    "objectID": "2019_isl/MD/Good.html",
    "href": "2019_isl/MD/Good.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Need to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nNeed to anticipate changing operating points and contexts.\n\nand uncertainty in estimating those!\n\n\n\n\n   \n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research, 13(Oct), pp.2813-2869."
  },
  {
    "objectID": "2019_isl/MD/Good.html#some-things-we-have-learned",
    "href": "2019_isl/MD/Good.html#some-things-we-have-learned",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Need to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nNeed to anticipate changing operating points and contexts.\n\nand uncertainty in estimating those!\n\n\n\n\n   \n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research, 13(Oct), pp.2813-2869."
  },
  {
    "objectID": "2019_isl/MD/Way.html",
    "href": "2019_isl/MD/Way.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\n \n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform if needed).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance.\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\nSee (Flach & Kull, NIPS 2015) for a deeper analysis of this.\n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights not requiring further measurements iff they have parallel ROC isometrics.\n\n \n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights possibly requiring further measurements iff ROC isometrics are straight.\n\n \n\n\n\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2019_isl/MD/Way.html#towards-measurement-theory-for-ml",
    "href": "2019_isl/MD/Way.html#towards-measurement-theory-for-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\n \n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform if needed).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance.\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\nSee (Flach & Kull, NIPS 2015) for a deeper analysis of this.\n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights not requiring further measurements iff they have parallel ROC isometrics.\n\n \n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights possibly requiring further measurements iff ROC isometrics are straight.\n\n \n\n\n\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2019_isl/MD/Scales.html",
    "href": "2019_isl/MD/Scales.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Stevens’ levels of measurement (1946)\ndimensional analysis in physics\ndo statistical quantities have dimensions?\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: ratios are meaningful\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added/subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\n \n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose lengths in \\(x\\), \\(y\\), \\(z\\) directions as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2019_isl/MD/Scales.html#scales-units-and-dimensions",
    "href": "2019_isl/MD/Scales.html#scales-units-and-dimensions",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Stevens’ levels of measurement (1946)\ndimensional analysis in physics\ndo statistical quantities have dimensions?\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: ratios are meaningful\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added/subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\n \n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose lengths in \\(x\\), \\(y\\), \\(z\\) directions as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2019_isl/MD/Intro.html",
    "href": "2019_isl/MD/Intro.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_isl/MD/Intro.html#assessing-performance-is-hard",
    "href": "2019_isl/MD/Intro.html#assessing-performance-is-hard",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_isl/MD/Latent.html",
    "href": "2019_isl/MD/Latent.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2019_isl/MD/Latent.html#latent-variable-models",
    "href": "2019_isl/MD/Latent.html#latent-variable-models",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2019_isl/MD/Bad.html",
    "href": "2019_isl/MD/Bad.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "We now see chronic over-reporting of performance measures without justification: - e.g. accuracy/error rate and F-score and AUC - e.g. MSE and MAE\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\nUse case determines performance measure.\n\n\n\nBoth can be used to evaluate predictive performance, but - Mean Squared Error gives expected misclassification loss if predicted probabilities are thresholded given known deployment class distribution; - Mean Absolute Error gives expected loss if class distribution is guessed wrongly (or classifier uses predicted probabilities to make stochastic predictions).\n\n\n\n\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery, pp.1-43."
  },
  {
    "objectID": "2019_isl/MD/Bad.html#so-more-is-better",
    "href": "2019_isl/MD/Bad.html#so-more-is-better",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "We now see chronic over-reporting of performance measures without justification: - e.g. accuracy/error rate and F-score and AUC - e.g. MSE and MAE\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\nUse case determines performance measure.\n\n\n\nBoth can be used to evaluate predictive performance, but - Mean Squared Error gives expected misclassification loss if predicted probabilities are thresholded given known deployment class distribution; - Mean Absolute Error gives expected loss if class distribution is guessed wrongly (or classifier uses predicted probabilities to make stochastic predictions).\n\n\n\n\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery, pp.1-43."
  },
  {
    "objectID": "2019_isl/MD/Hard.html",
    "href": "2019_isl/MD/Hard.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units and dimensions?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_isl/MD/Hard.html#assessing-performance-is-hard",
    "href": "2019_isl/MD/Hard.html#assessing-performance-is-hard",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units and dimensions?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_isl/MD/Outlook.html",
    "href": "2019_isl/MD/Outlook.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\nFor more information, see my project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2019_isl/MD/Outlook.html#outlook",
    "href": "2019_isl/MD/Outlook.html#outlook",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\nFor more information, see my project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2019_isl/MD/Ugly.html",
    "href": "2019_isl/MD/Ugly.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\n\n\n\nPR curve\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2019_isl/MD/Ugly.html#where-it-can-get-messy",
    "href": "2019_isl/MD/Ugly.html#where-it-can-get-messy",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\n\n\n\nPR curve\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2022_ecir/MD/All.html",
    "href": "2022_ecir/MD/All.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "I’m primarily a machine learner, but also work in AI and data science.\nI don’t know much about IR, but have thought long and hard about performance and calibration of ML classifiers.\nI think some of these ideas extend to IR, but would be very interested to hear your feedback.\nDisclaimer: I am not a statistician! \n\n\nQ1: Why is \\(F_1\\) the harmonic mean of precision and recall?\n\nIt’s a choice, it could equally well have been an arithmetic or geometric mean. \nIt corresponds to averaging the mistakes a classifier makes. \nAnother reason. \n\n\n\n\nQ2: When is \\(F_1\\) preferred over accuracy-based measures (micro/macro-accuracy)?\n\nWhen we have many more negatives than positives. \nWhen true negatives don’t add value. \nAnother reason. \n\n\n\n\nQ3: If we use \\(F_{1/2}\\), then…\n\nPrecision gets twice the weight of recall. \nPrecision gets four times the weight of recall. \nNeither. \n\n\n\n\nCommon definition: \\(F_1 = \\frac{2prec\\cdot rec}{prec+rec}\\).\nAs harmonic mean: \\(\\frac{1}{F_1} = \\left(\\frac{1}{rec} + \\frac{1}{prec}\\right)/2\\). \nPeter’s preferred definition: \\[F_{1} = \\frac{TP}{TP + {\\color{red}{\\frac{FN+FP}{2}}}} = \\frac{2TP}{2TP + FN+FP}\\] \n\n\n\n\\(\\frac{1}{F_1} = \\left(\\frac{1}{rec} + \\frac{1}{prec}\\right)/2\\)\n\\(F_{1} = \\frac{2TP}{2TP + FN+FP}\\)\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP            & FN            & Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\n\n\n\\(1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\)\n\\(F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\)\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(AM(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTowards max (min) the mean emphasises large (small) values.\n\n\n\n\nPrecision-recall curves considered harmful\nWork in progress on PRG curves\nMore sophisticated measurement models"
  },
  {
    "objectID": "2022_ecir/MD/All.html#introduction",
    "href": "2022_ecir/MD/All.html#introduction",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "I’m primarily a machine learner, but also work in AI and data science.\nI don’t know much about IR, but have thought long and hard about performance and calibration of ML classifiers.\nI think some of these ideas extend to IR, but would be very interested to hear your feedback.\nDisclaimer: I am not a statistician! \n\n\nQ1: Why is \\(F_1\\) the harmonic mean of precision and recall?\n\nIt’s a choice, it could equally well have been an arithmetic or geometric mean. \nIt corresponds to averaging the mistakes a classifier makes. \nAnother reason. \n\n\n\n\nQ2: When is \\(F_1\\) preferred over accuracy-based measures (micro/macro-accuracy)?\n\nWhen we have many more negatives than positives. \nWhen true negatives don’t add value. \nAnother reason. \n\n\n\n\nQ3: If we use \\(F_{1/2}\\), then…\n\nPrecision gets twice the weight of recall. \nPrecision gets four times the weight of recall. \nNeither. \n\n\n\n\nCommon definition: \\(F_1 = \\frac{2prec\\cdot rec}{prec+rec}\\).\nAs harmonic mean: \\(\\frac{1}{F_1} = \\left(\\frac{1}{rec} + \\frac{1}{prec}\\right)/2\\). \nPeter’s preferred definition: \\[F_{1} = \\frac{TP}{TP + {\\color{red}{\\frac{FN+FP}{2}}}} = \\frac{2TP}{2TP + FN+FP}\\] \n\n\n\n\\(\\frac{1}{F_1} = \\left(\\frac{1}{rec} + \\frac{1}{prec}\\right)/2\\)\n\\(F_{1} = \\frac{2TP}{2TP + FN+FP}\\)\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP            & FN            & Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\n\n\n\\(1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\)\n\\(F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\)\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(AM(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTowards max (min) the mean emphasises large (small) values.\n\n\n\n\nPrecision-recall curves considered harmful\nWork in progress on PRG curves\nMore sophisticated measurement models"
  },
  {
    "objectID": "2022_ecir/MD/All.html#roc-plots-101",
    "href": "2022_ecir/MD/All.html#roc-plots-101",
    "title": "Peter Flach Slides",
    "section": "ROC plots 101",
    "text": "ROC plots 101\n   \nShows how true and false positive rate co-vary with decision threshold.\n\nWhy ROC plots are great\n\nuniversal baselines - ascending diagonal gives expected performance of baseline (random) model.\nlinear interpolation - points on connecting line segments achieve same performance under specific class trade-offs.\nPareto front - linear interpolation gives ROC convex hull (ROCCH).\narea under curve - meaningful measure of ranking performance and expected accuracy.\ncalibration - ROCCH segments can be converted into meaningful probabilities.\n\n\n\nLinear interpolation\nAny point on a straight line between thresholds (or classifiers) A and B can be achieved by making a suitably biased random choice between them.\nIf that line has slope \\(Neg/Pos\\) (or 1) then all points on the line achieve the same micro-accuracy (or macro-accuracy).\nThis can be generalised to other trade-offs between classes (e.g., misclassification costs).\n\n\nArea under ROC curve (AUROC)\nThis estimates the probability that a randomly selected positive is ranked before a randomly selected negative.\nIt is also linearly related to expected classification performance if thresholds are set to make a particular proportion of positive predictions (pred pos rate).\n\\[\\int_0^1 acc\\ d\\ rate = \\pi(1-\\pi)(2AUROC-1)+1/2\\]\nHernandez-Orallo, Flach, Ferri. JMLR 13(91), 2012.\n\n\nCalibration\nSlopes of ROCCH segments are empirical likelihood ratios associated with score intervals, and can be used to obtain calibrated probabilities (isotonic regression).\nIf a perfectly calibrated classifier assigns score \\({\\color{red}c}\\) to an instance, then the instance is on the decision boundary for \\(acc_{\\color{red}c} = 2{\\color{red}c}\\pi tpr + 2{\\color{red}c}(1-\\pi) fpr\\).\nSong et al. Classifier Calibration: How to assess and improve predicted class probabilities: a survey. arXiv\n\n\nFrom ROC plots to PR plots\n   \nThere is a point-to-point correspondence between ROC space and PR space.\n\n\nWhy PR plots aren’t great\n\nnon-universal baselines - random performance gives horizontal line which depends on class distribution.\nnon-linear interpolation - iso-\\(F_{\\beta}\\) lines are hyperbolic.\nPareto front is well-defined but non-convex.\nuninterpretable area - because of incoherence of taking arithmetic mean of precision values and unachievable region.\nno calibration.\n\n\n\nFrom PR plots to PRGain plots\n   \nFlach and Kull. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\nWhy PRG plots are great\n\nbaseline - descending diagonal gives expected performance of always-positive classifier  (\\(rec=1, prec=\\pi, F_1=\\frac{2\\pi}{\\pi+1}\\)).\nlinear interpolation is restored.\nPareto front is once again convex.\ninterpretable area - AUPRG is related to expected \\(F_1\\) when operating points are chosen in a particular way.\ncalibration - scores can be converted into values of \\(\\beta\\) such that the instance is on the \\(F_{\\beta}\\) decision boundary.\n\n\n\nHow did we do it?\n\nTake reciprocals: \\(prec = TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP\\) \\(rec = TP/(TP+FN) \\rightarrow 1/rec = 1+FN/TP\\)\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\nPRG can rank models differently from PR\n\n\n\nfrom ROC via PR to PRG\n\n\nSolid line has higher AUROC and AUPRG but lower AUPR than dashed line.\n\n\nCalibrated scores from PRG curves\n   \nLeft: scores calibrated for \\(acc_{c}\\).\nRight: scores calibrated for \\(F_{\\beta}\\)."
  },
  {
    "objectID": "2022_ecir/MD/All.html#work-in-progress-on-prg-curves",
    "href": "2022_ecir/MD/All.html#work-in-progress-on-prg-curves",
    "title": "Peter Flach Slides",
    "section": "Work in progress on PRG curves",
    "text": "Work in progress on PRG curves\n\\(AUPRG = \\frac{\\pi}{1-\\pi}\\int \\frac{tpr-fpr}{tpr^3}\\ d\\ tpr\\)\n \n\nWeighted ROC curves\n   \nInstance weights allow us to translate PRG curves back to weighted ROC curves with the same area.\n\n\nInstance weights\nLet \\(r\\) and \\(s\\) be the true positive rates that obtain when thresholding just before or just after a positive example, then its weight is \\(\\frac{\\pi}{1-\\pi}\\frac{1}{rs}\\).\nHorizontal movement in ROC space corresponds to changes in precision which is influenced by both positives and negatives, but can nevertheless be precisely characterised in a similar way.\n\n\nNon-destructive truncation\nIn the NIPS’15 paper we truncated the PR curve so that \\(\\pi\\leq rec\\leq 1\\).\nBefore truncating we can pad the ranking at the front with \\(\\frac{\\pi}{1-\\pi}Pos\\) pseudo-instances, all labelled positive.\nThis gives rise to adjusted measures, e.g.  \\(rec'=\\frac{(1-\\pi)TP+\\pi Pos}{Pos}\\) and \\(recG'=\\frac{TP}{(1-\\pi)TP+\\pi Pos}\\)."
  },
  {
    "objectID": "2022_ecir/MD/All.html#more-sophisticated-measurement-models",
    "href": "2022_ecir/MD/All.html#more-sophisticated-measurement-models",
    "title": "Peter Flach Slides",
    "section": "More sophisticated measurement models",
    "text": "More sophisticated measurement models\n\nWhat you see is not what you want: estimating task difficulty and model ability\nUnderstanding why performance differences occur\n\n\nLatent variable models\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\nBeta-IRT\n   \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\nAdaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\n\n\nCAT results\n \n\n\nMore here\n\nChen, Silva Filho, Prudencio, Diethe, Flach. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\nSong and Flach. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. IJ Interactive Multimedia & AI 6(5), 2021.\n\n\n\nMeasurement and causality\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., if the classes were re-balanced (counterfactual intervention) the difference in performance would disappear. \n\nIn empirical ML we usually can carry out interventions (aka ablation study)."
  },
  {
    "objectID": "2022_ecir/MD/All.html#to-conclude",
    "href": "2022_ecir/MD/All.html#to-conclude",
    "title": "Peter Flach Slides",
    "section": "To conclude",
    "text": "To conclude\nPerhaps surprisingly, a definitive account of key measurement concepts such as scales, units, and dimensions is still missing.\nStevens’ typology (nominal, ordinal, interval, ratio) is well-known but limited: e.g., it doesn’t cover scales bounded from both sides (probabilities!).\nIn physics, quantities are understood to have an associated dimension, but these can cancel (angles, percentages) and don’t allow for transcendental functions (logs).\n\nTo conclude (2)\nThese issues notwithstanding, performance evaluation in ML and IR is often formulaic and simplistic.\nIncluding every performance indicator you can think of may make the big table look impressive, but doesn’t necessarily exude confidence that you know what you’re doing.\nIndicators such as accuracy (for classification), AUC (for ranking), Brier score (for probability estimation) should really be thought of as different ‘dimensions’ as in physics. What is your use case?\n\n\nTo conclude (3)\nProper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement scales for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\n\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Hao Song, Su Whan Baek, and many others."
  },
  {
    "objectID": "2023_munich/index.html",
    "href": "2023_munich/index.html",
    "title": "The highs and lows of performance evaluation",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall ( = true positive rate)? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is neither likely nor under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for given precision-recall trade-off.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2023_munich/index.html#why-care-about-measurement",
    "href": "2023_munich/index.html#why-care-about-measurement",
    "title": "The highs and lows of performance evaluation",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall ( = true positive rate)? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is neither likely nor under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for given precision-recall trade-off.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2023_munich/index.html#scales-units-dimensions-and-types",
    "href": "2023_munich/index.html#scales-units-dimensions-and-types",
    "title": "The highs and lows of performance evaluation",
    "section": "Scales, units, dimensions and types",
    "text": "Scales, units, dimensions and types\nPerhaps surprisingly, there doesn’t seem to be a definitive framework to link all these concepts together.\nWe’ll look at it from a few perspectives:\n\nLevels of measurement\nThe physics perspective\nThe computer science perspective"
  },
  {
    "objectID": "2023_munich/index.html#levels-of-measurement",
    "href": "2023_munich/index.html#levels-of-measurement",
    "title": "The highs and lows of performance evaluation",
    "section": "Levels of measurement",
    "text": "Levels of measurement\n   \nEarly proposal from a psychologist (Stevens, 1946), still influential although somewhat rigid and limited.\n\nStevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”.\n\n\nAdmissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above.\n\n\nLevels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning! \n\n\nAlternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2023_munich/index.html#the-physics-perspective",
    "href": "2023_munich/index.html#the-physics-perspective",
    "title": "The highs and lows of performance evaluation",
    "section": "The physics perspective",
    "text": "The physics perspective\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added or subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\n\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\nDimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\).\n\n\n\n\nHow to build on this in data science and AI?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…"
  },
  {
    "objectID": "2023_munich/index.html#the-computer-science-perspective",
    "href": "2023_munich/index.html#the-computer-science-perspective",
    "title": "The highs and lows of performance evaluation",
    "section": "The computer science perspective",
    "text": "The computer science perspective\n\nAbstract data types can be adapted to the situation.\n\nprovide relevant meta-data about measurements\nlink to useful operations.\n\nIn particular, higher-order functional languages such as Haskell allow reasoning with and about types.\n\nThis provides a formal language and logic for measurement meta-data.\n\nThe challenge is to develop a generally agreed “Systeme international” of ML measurements.\n\n\nExample: Shannon entropy\n \n\n\nExample: Scoring rules"
  },
  {
    "objectID": "2023_munich/index.html#you-cant-always-measure-what-you-want",
    "href": "2023_munich/index.html#you-cant-always-measure-what-you-want",
    "title": "The highs and lows of performance evaluation",
    "section": "You can’t always measure what you want…",
    "text": "You can’t always measure what you want…\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those latent variable models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\nIRT from a machine learning perspective\n \n\n\\(\\theta_i\\): ability of participant \\(i\\)\n\\(\\delta_j\\), \\(a_j\\): difficulty & discrimination of item \\(j\\)\n\\(x_{ij}\\): binary response (correct/incorrect)\n\n\n\nBeta-IRT\n \n\ncontinuous responses \\(p_{ij}\\)\nabilities & difficulties \\(\\in [0,1]\\)\n\n\n\nBeta-IRT: flexible Item Characteristic Curves\n \n\ndiscrimination \\(a_j\\) can be negative, indicating an item that confuses high-ability participants! \n\n\n\nIdea 1: Identifying noisy examples\n \n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\n\n\n\nIdea 2: Adaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\n\n\nCAT results\n \n\nSong, H. and Flach, P., 2020. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Int J Interactive Multimedia and AI 2021."
  },
  {
    "objectID": "2023_munich/index.html#outlook",
    "href": "2023_munich/index.html#outlook",
    "title": "The highs and lows of performance evaluation",
    "section": "Outlook",
    "text": "Outlook\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., with re-balanced classes (counterfactual intervention) the difference in performance would disappear. \n\nNB. In empirical ML we can actually carry out interventions, which makes causal inference a whole lot easier!"
  },
  {
    "objectID": "2023_munich/index.html#concluding-remarks",
    "href": "2023_munich/index.html#concluding-remarks",
    "title": "The highs and lows of performance evaluation",
    "section": "Concluding remarks",
    "text": "Concluding remarks\nProper treatment of performance evaluation in data science and AI requires a sophisticated measurement framework with the following components: - Coherent types and meta-data for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute; papers, code and videos can be accessed here.\nMany thanks to Hao Song, the Research Associate on the project; and collaborators Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Raul Santos-Rodriguez and many others."
  },
  {
    "objectID": "2022_leuven/index.html#why-care-about-measurement",
    "href": "2022_leuven/index.html#why-care-about-measurement",
    "title": "The highs and lows of performance evaluation",
    "section": "Why care about measurement?",
    "text": "Why care about measurement?\nMeasurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\nPerformance measurement is easy…\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n…or is it?\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is (a) very unlikely, and (b) not under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \nAn early result: Precision-Recall-Gain curves\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\nHow we fixed it: change of scale\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\nEt voila!\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for given precision-recall trade-off.\n\nWhat I will talk about\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2022_leuven/index.html#scales-units-dimensions-and-types",
    "href": "2022_leuven/index.html#scales-units-dimensions-and-types",
    "title": "The highs and lows of performance evaluation",
    "section": "Scales, units, dimensions and types",
    "text": "Scales, units, dimensions and types\nPerhaps surprisingly, there doesn’t seem to be a definitive framework to link all these concepts together.\nWe’ll look at it from a few perspectives:\n\nLevels of measurement\nThe physics perspective\nThe computer science perspective"
  },
  {
    "objectID": "2022_leuven/index.html#levels-of-measurement",
    "href": "2022_leuven/index.html#levels-of-measurement",
    "title": "The highs and lows of performance evaluation",
    "section": "Levels of measurement",
    "text": "Levels of measurement\n   \nEarly proposal from a psychologist (Stevens, 1946), still influential although somewhat rigid and limited.\nStevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”.\nAdmissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above.\nLevels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning! \nAlternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2022_leuven/index.html#the-physics-perspective",
    "href": "2022_leuven/index.html#the-physics-perspective",
    "title": "The highs and lows of performance evaluation",
    "section": "The physics perspective",
    "text": "The physics perspective\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added or subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\n\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\nDimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\).\n\n\nHow to build on this in data science and AI?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…"
  },
  {
    "objectID": "2022_leuven/index.html#the-computer-science-perspective",
    "href": "2022_leuven/index.html#the-computer-science-perspective",
    "title": "The highs and lows of performance evaluation",
    "section": "The computer science perspective",
    "text": "The computer science perspective\n\nAbstract data types can be adapted to the situation.\n\nprovide relevant meta-data about measurements\nlink to useful operations.\n\nIn particular, higher-order functional languages such as Haskell allow reasoning with and about types.\n\nThis provides a formal language and logic for measurement meta-data.\n\nThe challenge is to develop a generally agreed “Systeme international” of ML measurements.\n\nExample: Shannon entropy\n \nExample: Scoring rules"
  },
  {
    "objectID": "2022_leuven/index.html#you-cant-always-measure-what-you-want",
    "href": "2022_leuven/index.html#you-cant-always-measure-what-you-want",
    "title": "The highs and lows of performance evaluation",
    "section": "You can’t always measure what you want…",
    "text": "You can’t always measure what you want…\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those latent variable models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\nIRT from a machine learning perspective\n \n\n\\(\\theta_i\\): ability of participant \\(i\\)\n\\(\\delta_j\\), \\(a_j\\): difficulty & discrimination of item \\(j\\)\n\\(x_{ij}\\): binary response (correct/incorrect)\n\nBeta-IRT\n \n\ncontinuous responses \\(p_{ij}\\)\nabilities & difficulties \\(\\in [0,1]\\)\n\nBeta-IRT: flexible Item Characteristic Curves\n \n\ndiscrimination \\(a_j\\) can be negative, indicating an item that confuses high-ability participants! \n\nIdea 1: Identifying noisy examples\n \n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\n\nIdea 2: Adaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\nCAT results\n \n\nSong, H. and Flach, P., 2020. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Int J Interactive Multimedia and AI 2021."
  },
  {
    "objectID": "2022_leuven/index.html#outlook",
    "href": "2022_leuven/index.html#outlook",
    "title": "The highs and lows of performance evaluation",
    "section": "Outlook",
    "text": "Outlook\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., with re-balanced classes (counterfactual intervention) the difference in performance would disappear. \n\nNB. In empirical ML we can actually carry out interventions, which makes causal inference a whole lot easier!"
  },
  {
    "objectID": "2022_leuven/index.html#concluding-remarks",
    "href": "2022_leuven/index.html#concluding-remarks",
    "title": "The highs and lows of performance evaluation",
    "section": "Concluding remarks",
    "text": "Concluding remarks\nProper treatment of performance evaluation in data science and AI requires a sophisticated measurement framework with the following components: - Coherent types and meta-data for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute; papers, code and videos can be accessed here.\nMany thanks to Hao Song, the Research Associate on the project; and collaborators Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Raul Santos-Rodriguez and many others."
  },
  {
    "objectID": "web/plugin/markdown/example.html",
    "href": "web/plugin/markdown/example.html",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 1.1\nNote: This will only appear in the speaker notes window.\n\n\n\nContent 1.2\n\n\n\nContent 2.1\n\n\n\nContent 3.1\n\n\n\nContent 3.2"
  },
  {
    "objectID": "web/plugin/markdown/example.html#external-1.1",
    "href": "web/plugin/markdown/example.html#external-1.1",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 1.1\nNote: This will only appear in the speaker notes window."
  },
  {
    "objectID": "web/plugin/markdown/example.html#external-1.2",
    "href": "web/plugin/markdown/example.html#external-1.2",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 1.2"
  },
  {
    "objectID": "web/plugin/markdown/example.html#external-2",
    "href": "web/plugin/markdown/example.html#external-2",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 2.1"
  },
  {
    "objectID": "web/plugin/markdown/example.html#external-3.1",
    "href": "web/plugin/markdown/example.html#external-3.1",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 3.1"
  },
  {
    "objectID": "web/plugin/markdown/example.html#external-3.2",
    "href": "web/plugin/markdown/example.html#external-3.2",
    "title": "Markdown Demo",
    "section": "",
    "text": "Content 3.2"
  },
  {
    "objectID": "2019_aaai/MD/Good.html",
    "href": "2019_aaai/MD/Good.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Need to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nNeed to anticipate changing operating points and contexts.\n\nand uncertainty in estimating those!"
  },
  {
    "objectID": "2019_aaai/MD/Good.html#some-things-we-have-learned",
    "href": "2019_aaai/MD/Good.html#some-things-we-have-learned",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Need to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nNeed to anticipate changing operating points and contexts.\n\nand uncertainty in estimating those!"
  },
  {
    "objectID": "2019_aaai/MD/Way.html",
    "href": "2019_aaai/MD/Way.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\n \n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform if needed).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance.\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which you cannot calculate the concatenated value.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\nSee (Flach & Kull, NIPS 2015) for a deeper analysis of this.\n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights not requiring further measurements iff they have parallel ROC isometrics.\n\n \n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights possibly requiring further measurements iff ROC isometrics are straight."
  },
  {
    "objectID": "2019_aaai/MD/Way.html#towards-measurement-theory-for-ml",
    "href": "2019_aaai/MD/Way.html#towards-measurement-theory-for-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\n \n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform if needed).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance.\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which you cannot calculate the concatenated value.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\nSee (Flach & Kull, NIPS 2015) for a deeper analysis of this.\n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights not requiring further measurements iff they have parallel ROC isometrics.\n\n \n\n\n\n\nConcatenation of confusion matrices by cell-wise summing corresponds to arithmetic averaging of evaluation measures with weights possibly requiring further measurements iff ROC isometrics are straight."
  },
  {
    "objectID": "2019_aaai/MD/Intro.html",
    "href": "2019_aaai/MD/Intro.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_aaai/MD/Intro.html#assessing-performance-is-hard",
    "href": "2019_aaai/MD/Intro.html#assessing-performance-is-hard",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_aaai/MD/Bad.html",
    "href": "2019_aaai/MD/Bad.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "We now see chronic over-reporting of performance measures without justification: - e.g. accuracy/error rate and F-score and AUC - e.g. MSE and MAE\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\nUse case determines performance measure.\n\n\n\nBoth can be used to evaluate predictive performance, but - Mean Squared Error gives expected misclassification loss if predicted probabilities are thresholded given known deployment class distribution; - Mean Absolute Error gives expected loss if class distribution is wrongly estimated (or classifier uses predicted probabilities to make stochastic predictions)."
  },
  {
    "objectID": "2019_aaai/MD/Bad.html#so-more-is-better",
    "href": "2019_aaai/MD/Bad.html#so-more-is-better",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "We now see chronic over-reporting of performance measures without justification: - e.g. accuracy/error rate and F-score and AUC - e.g. MSE and MAE\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\nUse case determines performance measure.\n\n\n\nBoth can be used to evaluate predictive performance, but - Mean Squared Error gives expected misclassification loss if predicted probabilities are thresholded given known deployment class distribution; - Mean Absolute Error gives expected loss if class distribution is wrongly estimated (or classifier uses predicted probabilities to make stochastic predictions)."
  },
  {
    "objectID": "2019_aaai/MD/Hard.html",
    "href": "2019_aaai/MD/Hard.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_aaai/MD/Hard.html#assessing-performance-is-hard",
    "href": "2019_aaai/MD/Hard.html#assessing-performance-is-hard",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Quantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2019_aaai/MD/Outlook.html",
    "href": "2019_aaai/MD/Outlook.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - e.g., inspired by item-response theory, see our forthcoming AISTATS paper - Causal models to allow for counterfactual reasoning.\nFor more information, see my project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2019_aaai/MD/Outlook.html#outlook",
    "href": "2019_aaai/MD/Outlook.html#outlook",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - e.g., inspired by item-response theory, see our forthcoming AISTATS paper - Causal models to allow for counterfactual reasoning.\nFor more information, see my project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2019_aaai/MD/Ugly.html",
    "href": "2019_aaai/MD/Ugly.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\n\n\n\nPR curve"
  },
  {
    "objectID": "2019_aaai/MD/Ugly.html#where-it-can-get-messy",
    "href": "2019_aaai/MD/Ugly.html#where-it-can-get-messy",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\n\n\n\nPR curve"
  },
  {
    "objectID": "2020_ds/MD/Measurement.html",
    "href": "2020_ds/MD/Measurement.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\nConcatenate then measure gives the same result as measure then calculate.\n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform, as in cross-validation).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance (or made uniform, as in stratified cross-validation).\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2020_ds/MD/Measurement.html#towards-measurement-theory-for-ml",
    "href": "2020_ds/MD/Measurement.html#towards-measurement-theory-for-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\nConcatenate then measure gives the same result as measure then calculate.\n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform, as in cross-validation).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance (or made uniform, as in stratified cross-validation).\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2020_ds/MD/Dimensions.html",
    "href": "2020_ds/MD/Dimensions.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Physical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added, quantities need to be commensurable (have the same dimension).\n\nNB. This gives priority to additive scales!\n\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose \\(L_x\\), \\(L_y\\), \\(L_z\\) as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2020_ds/MD/Dimensions.html#units-dimensions-and-types",
    "href": "2020_ds/MD/Dimensions.html#units-dimensions-and-types",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Physical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added, quantities need to be commensurable (have the same dimension).\n\nNB. This gives priority to additive scales!\n\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose \\(L_x\\), \\(L_y\\), \\(L_z\\) as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2020_ds/MD/Scales.html",
    "href": "2020_ds/MD/Scales.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\\[F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\]\n\\[1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\] \n\n\n\n\nLinearise: e.g., \\[prec=TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP\\]\nMap \\([1,1/\\pi]\\) back to \\([0,1]\\): e.g., \\[precG = \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP\\] \n\n\n\n\n   \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2020_ds/MD/Scales.html#change-of-scale-examples-in-ml",
    "href": "2020_ds/MD/Scales.html#change-of-scale-examples-in-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\\[F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\]\n\\[1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\] \n\n\n\n\nLinearise: e.g., \\[prec=TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP\\]\nMap \\([1,1/\\pi]\\) back to \\([0,1]\\): e.g., \\[precG = \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP\\] \n\n\n\n\n   \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2020_ds/MD/Scales.html#squared-loss-and-log-loss",
    "href": "2020_ds/MD/Scales.html#squared-loss-and-log-loss",
    "title": "Peter Flach Slides",
    "section": "Squared loss and Log-loss",
    "text": "Squared loss and Log-loss\n\nThese are most commonly used to evaluate probability estimates against ‘ideal’ probabilities 0 and 1.\nAlternatively, they can be interpreted as expected misclassification loss, aggregating over all possible skews (class prevalence or cost proportion).\nFrom the latter perspective they differ only in the scale on which skews are measured.\n\n\nCost-sensitive classification\n\nLoss at a particular operating point:\n\n\\[Q(t; \\pi , c_0, c_1) =  c_0 \\pi (1 -F_0(t)) + c_1 (1-\\pi) F_1(t)\\]\n\nRe-parametrising on an arithmetic scale:\n\n\\[Q(t; \\pi , b, c) =  b\\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right]\\]\n\nAssuming \\(b, c\\) independent:\n\n\\[L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right] dc \\]\n\n\nDeriving squared loss\n\\[L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right] dc \\]\n\nAssuming a calibrated probabilistic classifier, then \\(t=c\\) is optimal; with a budget \\(\\mathbb{E}[b]=2\\):\n\n\\[ L = \\pi \\int_0^1 s^{2} f_0(s) ds + (1-\\pi) \\int_0^1 (1-s)^{2} f_1(s) ds \\]\n\nThis is squared loss, also known as the Brier score. \n\n\n\nChanging the cost scale\n\nThe starting point is the same:\n\n\\[Q(t; \\pi , c_0, c_1) =  c_0 \\pi (1 -F_0(t)) + c_1 (1-\\pi) F_1(t)\\]\n\nRe-parametrising on a harmonic scale:\n\n\\[Q(t; \\pi , d, c) =  d\\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right]\\]\n\nAssuming \\(d, c\\) independent:\n\n\\[L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right] dc \\]\n\n\nDeriving log-loss\n\\[L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right] dc \\]\n\nAssuming a calibrated probabilistic classifier and a budget \\(\\mathbb{E}[d]=1/2\\):\n\n\\[ L = \\pi/2 \\int_0^1 -\\ln (1-s) f_0(s) ds + (1-\\pi)/2 \\int_0^1 -\\ln s f_1(s) ds \\]\n\nThis is log-loss. \n\n\n\nIllustration\n\nCalibration: poor (left), perfect (right).\nCost scale: arithmetic (blue), harmonic (red).\n\n   \nLog-loss emphasises extreme values of \\(c\\). \n\n\nSampled cost parameters\n   \nLeft: arithmetic; right: harmonic.\n\n\nMore here\nFlach, P., 2015. Cost-Sensitive Classification Meets Proper Scoring Rules. Second international workshop on learning over multiple contexts (LMCE’15) at ECML-PKDD 2015."
  },
  {
    "objectID": "2020_ds/MD/All.html",
    "href": "2020_ds/MD/All.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in machine learning and discovery science for at least two reasons: - Features are often are measurements on some scale, and we need to understand the properties of the scale, admissible operations, etc. - E.g., the arithmetic mean is not always appropriate. - Performance metrics are also measurements, and hence the same applies! - Taking expectations, area under curve etc. may not be coherent.\n\n\nUsing a calibrated measuring instrument (e.g., a ruler) we map the object under measurement \\(a\\) to a real number \\(M(a)\\).\nThis mapping should be such that if I concatenate two objects \\(a \\circ b\\) there should be a corresponding numerical operation \\(\\oplus\\) on the measurements (e.g., addition), establishing a scale.\n \n\n\n\nAveraging can also be understood in terms of concatenation: we are looking for \\(M(c)\\) for some \\(c\\) such that \\(M(a \\circ b) = M(c \\circ c)\\).\nClearly this gives a value in between \\(M(a)\\) and \\(M(b)\\). Other properties depend on the scale used.\nLet’s look at some examples.\n\n\n\n…I went on two bicycle rides. On Saturday my average speed was 20 km/h, on Sunday it was 30 km/h.\n\nConcatenating the two trips, I calculated my overall average speed as 25 km/h. What can I say about the two trips?\n\nThey were equally far (in distance).\nThey were equally long (in time). CORRECT! \nNeither.\n\n\n\n\n\n…I also did two rides with average speeds 20 km/h and 30 km/h.\n\nThis time I calculated my overall average speed as 24 km/h. What can I say about these two trips?\n\nThey were equally far (in distance). CORRECT! \nThey were equally long (in time).\nNeither.\n\n\n\n\n\nTrip 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\).\nTrip 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\).\nOverall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\).\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = AM(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = HM(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\n\n\nWhen we average ratios we are making assumptions:\n\nthe arithmetic mean assumes denominators stay the same;\nthe harmonic mean assumes numerators stay the same.\n\n\nAlternatively, we can use weighted means (either arithmetic or harmonic).\n\n\n\nI apply a binary classifier on two test sets A and B.\nOn A and B separately, the classifier achieves 70% and 80% accuracy (the proportion of correctly classified instances).\n\nWhen I combine A and B into a single test set and re-run the classifier its accuracy is 75%. What can I say about A and B? \n\nThey contain the same number of instances. \nThey contain the same number of positives. \nBoth. \nNeither. \n\n\n\n\n\n(same question, but now for recall = true positive rate)\nOn two other test sets C and D, the classifier achieves 70% and 80% recall (the proportion of correctly classified positives).\n\nWhen I combine C and D into a single test set and re-run the classifier its recall is 75%. What can I say about C and D?\n\nThey contain the same number of instances.\nThey contain the same number of positives.\nBoth.\nNeither.\n\n\n\n\n\n(same question, but now for precision)\nOn yet other test sets E and F, the classifier achieves 70% and 80% precision (the proportion of correct positive predictions).\n\nWhen I combine E and F into a single test set and re-run the classifier its precision is 75%. What can I say about E and F?\n\nThey contain the same number of instances.\nThey contain the same number of positives.\nBoth.\nNeither.\n\n\n\n\n\n(Q1: 1) \\(acc(A \\circ B) = AM(acc(A),acc(B))\\) implies A and B contain the same number of instances.\n(Q2: 2) \\(tpr(C \\circ D) = AM(tpr(C),tpr(D))\\) implies C and D contain the same number of positives.\n(Q3: 4) \\(prec(E \\circ F) = AM(prec(E),prec(F))\\) implies the classifier makes the same number of positive predictions on E and F.\n\n\n\n\nUsing the (unweighted) arithmetic mean on performance metrics needs to be justified:\n\nfor accuracy the test sets need to be equal in size (as in cross-validation);\nfor recall the class distributions need to be the same (stratified CV);\nfor precision the proportions of positive predictions need to be the same (??).\n\n\nArithmetically averaging precision is rarely justified. The same holds for F-score (more on that later). \n\n\n\n\nChanges of scale\n\nPrecision-recall curves and how to fix them\nHow log-loss relates to squared loss\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\nCausal models\n\nConclusions and outlook"
  },
  {
    "objectID": "2020_ds/MD/All.html#why-should-you-care-about-measurement",
    "href": "2020_ds/MD/All.html#why-should-you-care-about-measurement",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in machine learning and discovery science for at least two reasons: - Features are often are measurements on some scale, and we need to understand the properties of the scale, admissible operations, etc. - E.g., the arithmetic mean is not always appropriate. - Performance metrics are also measurements, and hence the same applies! - Taking expectations, area under curve etc. may not be coherent.\n\n\nUsing a calibrated measuring instrument (e.g., a ruler) we map the object under measurement \\(a\\) to a real number \\(M(a)\\).\nThis mapping should be such that if I concatenate two objects \\(a \\circ b\\) there should be a corresponding numerical operation \\(\\oplus\\) on the measurements (e.g., addition), establishing a scale.\n \n\n\n\nAveraging can also be understood in terms of concatenation: we are looking for \\(M(c)\\) for some \\(c\\) such that \\(M(a \\circ b) = M(c \\circ c)\\).\nClearly this gives a value in between \\(M(a)\\) and \\(M(b)\\). Other properties depend on the scale used.\nLet’s look at some examples.\n\n\n\n…I went on two bicycle rides. On Saturday my average speed was 20 km/h, on Sunday it was 30 km/h.\n\nConcatenating the two trips, I calculated my overall average speed as 25 km/h. What can I say about the two trips?\n\nThey were equally far (in distance).\nThey were equally long (in time). CORRECT! \nNeither.\n\n\n\n\n\n…I also did two rides with average speeds 20 km/h and 30 km/h.\n\nThis time I calculated my overall average speed as 24 km/h. What can I say about these two trips?\n\nThey were equally far (in distance). CORRECT! \nThey were equally long (in time).\nNeither.\n\n\n\n\n\nTrip 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\).\nTrip 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\).\nOverall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\).\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = AM(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = HM(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\n\n\nWhen we average ratios we are making assumptions:\n\nthe arithmetic mean assumes denominators stay the same;\nthe harmonic mean assumes numerators stay the same.\n\n\nAlternatively, we can use weighted means (either arithmetic or harmonic).\n\n\n\nI apply a binary classifier on two test sets A and B.\nOn A and B separately, the classifier achieves 70% and 80% accuracy (the proportion of correctly classified instances).\n\nWhen I combine A and B into a single test set and re-run the classifier its accuracy is 75%. What can I say about A and B? \n\nThey contain the same number of instances. \nThey contain the same number of positives. \nBoth. \nNeither. \n\n\n\n\n\n(same question, but now for recall = true positive rate)\nOn two other test sets C and D, the classifier achieves 70% and 80% recall (the proportion of correctly classified positives).\n\nWhen I combine C and D into a single test set and re-run the classifier its recall is 75%. What can I say about C and D?\n\nThey contain the same number of instances.\nThey contain the same number of positives.\nBoth.\nNeither.\n\n\n\n\n\n(same question, but now for precision)\nOn yet other test sets E and F, the classifier achieves 70% and 80% precision (the proportion of correct positive predictions).\n\nWhen I combine E and F into a single test set and re-run the classifier its precision is 75%. What can I say about E and F?\n\nThey contain the same number of instances.\nThey contain the same number of positives.\nBoth.\nNeither.\n\n\n\n\n\n(Q1: 1) \\(acc(A \\circ B) = AM(acc(A),acc(B))\\) implies A and B contain the same number of instances.\n(Q2: 2) \\(tpr(C \\circ D) = AM(tpr(C),tpr(D))\\) implies C and D contain the same number of positives.\n(Q3: 4) \\(prec(E \\circ F) = AM(prec(E),prec(F))\\) implies the classifier makes the same number of positive predictions on E and F.\n\n\n\n\nUsing the (unweighted) arithmetic mean on performance metrics needs to be justified:\n\nfor accuracy the test sets need to be equal in size (as in cross-validation);\nfor recall the class distributions need to be the same (stratified CV);\nfor precision the proportions of positive predictions need to be the same (??).\n\n\nArithmetically averaging precision is rarely justified. The same holds for F-score (more on that later). \n\n\n\n\nChanges of scale\n\nPrecision-recall curves and how to fix them\nHow log-loss relates to squared loss\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\nCausal models\n\nConclusions and outlook"
  },
  {
    "objectID": "2020_ds/MD/All.html#changes-of-scale",
    "href": "2020_ds/MD/All.html#changes-of-scale",
    "title": "Peter Flach Slides",
    "section": "Changes of scale",
    "text": "Changes of scale\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(AM(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\nComparing means\n \nTowards max (min) the mean emphasises large (small) values.\n\n\nChange of scale examples in ML\n\nPrecision-recall curves have many issues that can be solved with a change of scale.\nLoss measures such as log-loss and squared loss can be related to each other through a change of scale."
  },
  {
    "objectID": "2020_ds/MD/All.html#roc-curve-and-precision-recall-curve",
    "href": "2020_ds/MD/All.html#roc-curve-and-precision-recall-curve",
    "title": "Peter Flach Slides",
    "section": "ROC curve and precision-recall curve",
    "text": "ROC curve and precision-recall curve\n   \nIn contrast to ROC curves, PR curves don’t allow linear interpolation and don’t have a meaningful area under the curve. \n\n\\(F_{\\beta}\\)-score\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\\[F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\]\n\\[1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\]\n\n\nFixing PR curves through scale transformations\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\nEt voila!\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for a given \\(\\beta^2\\).\n\n### More here\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\nfrom ROC via PR to PRG"
  },
  {
    "objectID": "2020_ds/MD/All.html#squared-loss-and-log-loss",
    "href": "2020_ds/MD/All.html#squared-loss-and-log-loss",
    "title": "Peter Flach Slides",
    "section": "Squared loss and Log-loss",
    "text": "Squared loss and Log-loss\n\nThese are most commonly used to evaluate probability estimates against ‘ideal’ probabilities 0 and 1.\nAlternatively, they can be interpreted as expected misclassification loss, aggregating over all possible skews (class prevalence or cost proportion).\nFrom the latter perspective they differ only in the scale on which skews are measured.\n\n\nCost-sensitive classification\n\nLet $c_+$ be the cost of misclassifying a positive (i.e., a false negative) and $c_-$ the cost of misclassifying a negative (i.e., a false positive).\n$c=\\frac{c_{+}}{c_{+}+c_{-}}$ is the cost proportion.\nTwo ways to derive $c_+,c_-$ from \\(c\\):\n\nset a fixed budget $b=c_++c_-$, then $c_+=bc$ and $c_-=b(1-c)$.\nset a fixed budget $d=1/(1/c_++1/c_-)$, then $c_+=d/(1-c)$ and $c_-=d/c$.\n\nVarying \\(c\\) uniformly in \\([0,1]\\) and setting the decision threshold equal to \\(c\\), the first gives squared loss as expected loss, the second log-loss. \n\n\n\nNotation\n\n\n\n\n\n\n\n\nSymbol\nRange\nMeaning\n\n\n\n\n$c_{+}$, $c_{-}$\n$\\mathbb{R}^+$\ncost of misclassifying a positive/negative\n\n\n$c=\\frac{c_{+}}{c_{+}+c_{-}}$\n$[0,1]$\ncost proportion\n\n\n$\\pi$\n$[0,1]$\nproportion of positives\n\n\n\n$F_{+}(t)$, $F_{-}(t)$: true/false positive rate at threshold \\(t\\), interpreted as a cumulative distribution\n$f_{+}(s)$, $f_{-}(s)$: score densities for positive/negative class\n\n\nCost-sensitive classification\n\nLoss at a particular operating point:\n\n$$Q(t; \\pi , c_{+}, c_{-}) =  c_{+} \\pi (1 -F_{+}(t)) + c_{-} (1-\\pi) F_{-}(t)$$\n\nLet \\(b\\) be the arithmetic sum of $c_{+}, c_{-}$:\n\n$$Q(t; \\pi , b, c) =  b\\left[c \\pi (1 -F_{+}(t)) + (1-c) (1-\\pi) F_{-}(t)\\right]$$\n\nAssuming \\(b, c\\) independent:\n\n$$L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_{+}(t)) + (1-c) (1-\\pi) F_{-}(t)\\right] dc $$\n\n\nDeriving squared loss\n$$L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_{+}(t)) + (1-c) (1-\\pi) F_{-}(t)\\right] dc $$\n\nAssuming a calibrated probabilistic classifier, then \\(t=c\\) is optimal; with a budget \\(\\mathbb{E}[b]=2\\):\n\n$$ L = \\pi \\int_0^1 s^{2} f_{+}(s) ds + (1-\\pi) \\int_0^1 (1-s)^{2} f_{-}(s) ds $$\n\nThis is squared loss, also known as the Brier score.\n\n\n\nChanging the cost scale\n\nStarting again from loss at threshold \\(t\\):\n\n$$Q(t; \\pi , c_{+}, c_{-}) =  c_{+} \\pi (1 -F_{+}(t)) + c_{-} (1-\\pi) F_{-}(t)$$\n\nLet \\(d\\) be the harmonic sum of $c_{+}, c_{-}$:\n\n$$Q(t; \\pi , d, c) =  d\\left[\\frac{1}{1-c} \\pi (1 -F_{+}(t)) + \\frac{1}{c} (1-\\pi) F_{-}(t)\\right]$$\n\nAssuming \\(d, c\\) independent:\n\n$$L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_{+}(t)) + \\frac{1}{c} (1-\\pi) F_{-}(t)\\right] dc $$\n\n\nDeriving log-loss\n$$L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_{+}(t)) + \\frac{1}{c} (1-\\pi) F_{-}(t)\\right] dc $$\n\nAssuming a calibrated probabilistic classifier and a budget \\(\\mathbb{E}[d]=1/2\\):\n\n$$ L = \\pi/2 \\int_0^1 -\\ln (1-s) f_{+}(s) ds + (1-\\pi)/2 \\int_0^1 -\\ln s f_{-}(s) ds $$\n\nThis is log-loss.\n\n\n\nCost curves\n\nCalibration: poor (left), perfect (right).\nCost scale: arithmetic (blue), harmonic (red).\n\n   \nLog-loss emphasises extreme values of \\(c\\). \n\n\nMore here\nFlach, P., 2015. Cost-Sensitive Classification Meets Proper Scoring Rules. Second international workshop on learning over multiple contexts (LMCE’15) at ECML-PKDD 2015."
  },
  {
    "objectID": "2020_ds/MD/All.html#scales-units-dimensions-and-types",
    "href": "2020_ds/MD/All.html#scales-units-dimensions-and-types",
    "title": "Peter Flach Slides",
    "section": "Scales, units, dimensions and types",
    "text": "Scales, units, dimensions and types\nSo we’ve seen the use of a mathematical treatment of scales. What about things like units and dimensions?\nPerhaps surprisingly, there doesn’t seem to be a definitive framework to link all these concepts together. We’ll look at it from a few more perspectives:\n\nLevels of measurement\nThe physics perspective\nThe computer science perspective"
  },
  {
    "objectID": "2020_ds/MD/All.html#levels-of-measurement",
    "href": "2020_ds/MD/All.html#levels-of-measurement",
    "title": "Peter Flach Slides",
    "section": "Levels of measurement",
    "text": "Levels of measurement\n   \nEarly proposal from a psychologist (Stevens, 1946), still influential although somewhat rigid and limited.\n\nStevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”.\n\n\nAdmissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above.\n\n\nLevels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning! \n\n\nAlternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2020_ds/MD/All.html#the-physics-perspective",
    "href": "2020_ds/MD/All.html#the-physics-perspective",
    "title": "Peter Flach Slides",
    "section": "The physics perspective",
    "text": "The physics perspective\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added or subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\n\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\nDimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\)."
  },
  {
    "objectID": "2020_ds/MD/All.html#how-do-we-build-on-this-in-ml",
    "href": "2020_ds/MD/All.html#how-do-we-build-on-this-in-ml",
    "title": "Peter Flach Slides",
    "section": "How do we build on this in ML?",
    "text": "How do we build on this in ML?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…\n\n\n\n\nWhy we need flexibility\n\nLet \\(p\\) be the parameter of a Bernoulli distribution (e.g, coin comes up head with probability \\(p\\)). Then\n\nthe variance of this distribution (i.e., spread around the mean) is \\(p(1-p)\\);\nits entropy (i.e., information content of a coin toss on average) is \\(-p \\log p - (1-p) \\log (1-p)\\).\n\nAt first sight these seem very different things, and hence don’t share scale, unit, or dimension. \n\nHowever, I’m going to put forward an argument that they can be seen as different ways of measuring the same thing! \n\n\n\n\nContext: proper scoring rules\n\nScoring rule \\(\\phi(p,y)\\) returns the loss of predicting \\(p\\) for class \\(1\\) when the true class is \\(y\\)\n\n$\\phi : \\mathbb{P} \\times \\{0,1\\} \\mapsto \\mathbb{R}$\noften takes the form $\\phi(p,y) = y h(p) + (1-y) h(1-p)$\n\nExpected score \\(s(p,q) = \\mathbb{E}_{y \\sim q} \\phi(p,y)\\)\n\n$s : \\mathbb{P} \\times \\mathbb{P} \\mapsto \\mathbb{R}$\nwith the above form of \\(\\phi\\): $s(p,q) = q h(p) + (1-q) h(1-p)$\n\n\n\n\nGeneralised divergence and entropy\n\nDivergence \\(d(p,q) = s(p,q) - s(q,q)\\)\n\n$d : \\mathbb{P} \\times \\mathbb{P} \\mapsto \\mathbb{R}$.\nThe scoring rule is (strictly) proper if \\(p=q\\) is (sole) minimiser of \\(d(p,q)\\) for a given \\(q\\).\nNB. this turns an interval scale into a ratio scale.\n\nEntropy \\(e(q) = s(q,q)\\)\n\n$e : \\mathbb{P} \\mapsto \\mathbb{R}$\n\n\n\n\nLogarithmic scoring rule\n\\[\n\\begin{align}\nh(p) &= -\\log p  \\\\\\\\\n\\phi(p,y) &= -y \\log p - (1-y)\\log (1-p)  \\\\\\\\\ns(p,q) &= -q\\log p -(1-q)\\log (1-p)  \\\\\\\\\n\\\\ \\\\\\\\\nd(p,q) &= -q\\log \\frac{p}{q} - (1-q) \\frac{1-p}{1-q}  \\\\\\\\\ne(q) &= -q\\log q - (1-q)\\log (1-q)  \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nThe last two equations are known as Kullback-Leibler divergence and Shannon entropy.\n\n\nQuadratic scoring rule\n\\[\n\\begin{align}\nh(p) &= (1-p)^2 \\\\\\\\\n\\phi(p,y) &= y(1-p)^2+(1-y)p^2 \\\\\\\\\ns(p,q) &= q(1-p)^2+(1-q)p^2 \\\\\\\\\n\\\\ \\\\\\\\\nd(p,q) &= (p-q)^2 \\\\\\\\\ne(q) &= q(1-q) \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nThis scoring rule is also known as the Brier score (Brier, 1950).\n\n\nAnd therefore…\n\nBernoulli variance and Shannon entropy are both realisations of generalised entropy, using different scoring rules.\n\nIt would therefore make sense to treat them as having the same “type”, at least from this perspective.\n\nBTW Not a big surprise for (decision) tree lovers, as\n\nBernoulli variance aka Gini index is one way of measuring impurity of a node (as used in CART);\nShannon entropy is another (as used in ID3 and C4.5).\n\n\n\n\nScoring rules in a typed functional language\n \n\n\nShannon entropy as expected number of bits\n \n\n\nWhat’s my point?\n\nAbstract data types are more flexible than dimensions or scale types as they can be adapted to the situation of interest.\n\nprovide relevant meta-data about measurements\nlink to useful operations.\n\nIn particular, higher-order functional languages such as Haskell allow reasoning with and about types.\n\nThis provides a formal language and logic for measurement meta-data.\n\nThe challenge is to develop a generally agreed “Systeme international” of ML measurements."
  },
  {
    "objectID": "2020_ds/MD/All.html#and-finally",
    "href": "2020_ds/MD/All.html#and-finally",
    "title": "Peter Flach Slides",
    "section": "And finally…",
    "text": "And finally…\n\nYou can’t always measure what you want!\n\nLatent variable models\nCausal models"
  },
  {
    "objectID": "2020_ds/MD/All.html#latent-variable-models",
    "href": "2020_ds/MD/All.html#latent-variable-models",
    "title": "Peter Flach Slides",
    "section": "Latent variable models",
    "text": "Latent variable models\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\nBeta-IRT\n   \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\nAdaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\n\n\nCAT results\n \n\n\nMore here\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\nSong, H., and Flach, P., 2020. Towards Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Evaluating Progress in AI workshop at ECAI 2020."
  },
  {
    "objectID": "2020_ds/MD/All.html#causal-models",
    "href": "2020_ds/MD/All.html#causal-models",
    "title": "Peter Flach Slides",
    "section": "Causal models",
    "text": "Causal models\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., if the classes were re-balanced (counterfactual intervention) the difference in performance would disappear. \n\nNB. In empirical ML we can actually carry out interventions, which makes causal inference a whole lot easier!"
  },
  {
    "objectID": "2020_ds/MD/All.html#outlook",
    "href": "2020_ds/MD/All.html#outlook",
    "title": "Peter Flach Slides",
    "section": "Outlook",
    "text": "Outlook\nProper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Hao Song and many others."
  },
  {
    "objectID": "2020_ds/MD/Intro.html",
    "href": "2020_ds/MD/Intro.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Transparent machine learning requires knowledge of - how a model was built; - how a model makes decisions; - how well it can be expected to perform; - what its operating assumptions and limitations are.\n\n\n\nNeed to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nOperating points & contexts can change.\n\n   \n\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research 13(Oct), pp.2813-2869.\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery 33, pp.805-847.\n\n\n\n\n\n\nQuantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2020_ds/MD/Intro.html#transparency",
    "href": "2020_ds/MD/Intro.html#transparency",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Transparent machine learning requires knowledge of - how a model was built; - how a model makes decisions; - how well it can be expected to perform; - what its operating assumptions and limitations are.\n\n\n\nNeed to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nOperating points & contexts can change.\n\n   \n\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research 13(Oct), pp.2813-2869.\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery 33, pp.805-847.\n\n\n\n\n\n\nQuantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2020_ds/MD/Latent.html",
    "href": "2020_ds/MD/Latent.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2020_ds/MD/Latent.html#latent-variable-models",
    "href": "2020_ds/MD/Latent.html#latent-variable-models",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2020_ds/MD/Outlook.html",
    "href": "2020_ds/MD/Outlook.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\n\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2020_ds/MD/Outlook.html#outlook",
    "href": "2020_ds/MD/Outlook.html#outlook",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\n\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2020_ds/MD/Prelims.html",
    "href": "2020_ds/MD/Prelims.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Segment 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\) Segment 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\) Overall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\)\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = A(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = H(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(A(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTop (sensitive to small values) to bottom (sensitive to large values): harmonic, geometric, arithmetic, quadratic.\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: fixed zero, ratios are also meaningful\nTransformed scales: e.g. log-ratio\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nScores in an ensemble are often arithmetically averaged to obtain an overall score.\nBut what if the base classifiers are probability estimators? Do you \n\nContinue to use arithmetic mean? \nConvert to bits first (aka log-likelihoods)? \nUse geometric mean?"
  },
  {
    "objectID": "2020_ds/MD/Prelims.html#means-and-scales",
    "href": "2020_ds/MD/Prelims.html#means-and-scales",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Segment 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\) Segment 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\) Overall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\)\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = A(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = H(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(A(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTop (sensitive to small values) to bottom (sensitive to large values): harmonic, geometric, arithmetic, quadratic.\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: fixed zero, ratios are also meaningful\nTransformed scales: e.g. log-ratio\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nScores in an ensemble are often arithmetically averaged to obtain an overall score.\nBut what if the base classifiers are probability estimators? Do you \n\nContinue to use arithmetic mean? \nConvert to bits first (aka log-likelihoods)? \nUse geometric mean?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This website is an example of how the source code of the website flach.github.io/slides/ can be adapted to a Quarto website. The new Quarto source code can be found at the forked repository perellonieto/slides_flach.\nCurrently, the slides in section 2023 have been rendered directly as Quarto webpages. While slides in section 2022 have been rendered as RevealJS by Quarto.\nNotice that 2022_leuven (see original)slides are not divided on the correct slide content as the division between slides is specified in a different way.\nOn the other side, 2022_monash (see original) the title levels have been increased by one (e.g. ## Title for # Title), which divided all sections with a title of level 1 or 2 (# or ##) into a new slide. This is still not the same behaviour than the original slides flach.github.io that used \\n----\\n\\n to separate vertical sections of the presentation (as specified in the html index as data-separator=\"^\\n---\\n\\n\"). I have also tried to add the css format from the reveal.css file in the last one. However, the format does not look the same as the original. This needs to be checked.\nAnother details is that when Quarto generates the RevealJS slides, the resulting slides are part of an .html file (see 2022/monash example). In contrast, the original Jekyll version contains an .html file with the basic information and the markdown file as a data-markdown=\"MD/All.md\" (see source code)\n\n\n\nAdd style of the original slides (probably with the css files)\nUnderstand what is the required webpage layout"
  },
  {
    "objectID": "index.html#todos",
    "href": "index.html#todos",
    "title": "Home",
    "section": "",
    "text": "Add style of the original slides (probably with the css files)\nUnderstand what is the required webpage layout"
  },
  {
    "objectID": "2023_nightingale/index.html",
    "href": "2023_nightingale/index.html",
    "title": "AI in the time of chatGPT",
    "section": "",
    "text": "In the time of ChatGPT, artificial intelligence had become a marvel of the modern world, a magical creation that seemed almost alive. It was as if the machines had a soul, capable of understanding and empathizing with human emotions. ChatGPT was a symbol of this new era, a mysterious being with a secret language that only the initiated could understand. But amidst the awe and wonder, there were also whispers of fear, for no one knew what the future held in this age of AI.\n\n\n\n\nWhat ChatGPT is – and isn’t\nWe need to talk about (over)confidence\nAI in the time of ChatGPT"
  },
  {
    "objectID": "2023_nightingale/index.html#ai-in-the-time-of-chatgpt",
    "href": "2023_nightingale/index.html#ai-in-the-time-of-chatgpt",
    "title": "AI in the time of chatGPT",
    "section": "",
    "text": "In the time of ChatGPT, artificial intelligence had become a marvel of the modern world, a magical creation that seemed almost alive. It was as if the machines had a soul, capable of understanding and empathizing with human emotions. ChatGPT was a symbol of this new era, a mysterious being with a secret language that only the initiated could understand. But amidst the awe and wonder, there were also whispers of fear, for no one knew what the future held in this age of AI.\n\n\n\n\nWhat ChatGPT is – and isn’t\nWe need to talk about (over)confidence\nAI in the time of ChatGPT"
  },
  {
    "objectID": "2023_nightingale/index.html#what-chatgpt-is-and-isnt",
    "href": "2023_nightingale/index.html#what-chatgpt-is-and-isnt",
    "title": "AI in the time of chatGPT",
    "section": "What ChatGPT is – and isn’t",
    "text": "What ChatGPT is – and isn’t\n\nChatGPT = large language model + dialogue model\nWe’ll look at ways to think about its capabilities.\n\n\nNot just a large language model\n\nfrom https://blog.bytebytego.com/p/ep-44-how-does-ChatGPT-work\n\n\nTraining the dialogue model\n\nfrom https://openai.com/blog/ChatGPT\n\n\nWhat others say\n\nSometimes I think it’s as if aliens had landed and people haven’t realized because they speak very good English.\n\nGeoffrey Hinton in an interview with MIT Technology Review\n\n\nThe ultimate bullshit machine\n\nFor the bullshitter [all] bets are off: he is neither on the side of the true nor on the side of the false. His eye is not on the facts at all, as the eyes of the honest man and of the liar are, except insofar as they may be pertinent to his interest in getting away with what he says. He does not care whether the things he says describe reality correctly.\n\nHarry Frankfurt, On Bullshit. Princeton University Press, 2005.\n\n\nMansplaining-as-a-Service\n\n“If someone perceives my responses as mansplaining, I apologize and encourage them to provide specific feedback on how I can improve and be more respectful in my interactions.” (ChatGPT)\n\n\nDetour: “computer” chess\n \n\n\nA computer walks into a chess tournament…\n\n…and beats a chess grandmaster.\nDoes that say something about  - computers?  - humans?  - chess? \n\n\nCapturing the essence of human language\n\nI think we have to view this as a – potentially surprising – scientific discovery: that somehow in a neural net like ChatGPT’s it’s possible to capture the essence of what human brains manage to do in generating language.\n\nStephen Wolfram: What Is ChatGPT Doing … and Why Does It Work?\n\n\nCan ChatGPT do reasoning?\n\n\n\nTimeslots\n\n\n\n\nCan ChatGPT do reasoning? (2)\n\n\n\nTrophy & suitcase\n\n\n\n\nCan ChatGPT do reasoning? (3)\n\n\n\nCars\n\n\n\n\nCan ChatGPT do reasoning? (4)\n\nAmusing mistakes like these aside, it is rather remarkable that (limited) reasoning capabilities have arisen without having been explicitly trained on such tasks.\nThis demonstrates the surprising power of large language data.\n\n\n\n“Hallucination” and fact-checking\n\nPutting linguistic elements together in surprising and potentially novel ways is the essence of language, so “hallucination” or “confabulation” shouldn’t come as a surprise.\nThe following are two very different things:\n\n“Generate something that looks like a URL”;\n“Generate an existing and meaningful URL”.\n\nSome forms of fact-checking can be done post-hoc, but others will need to be built into the language model.\n\n\n\nHas AI passed the Turing Test?\nI am not aware of a formally run Turing Test with ChatGPT or one of the other LLM-driven chatbots, but…\n…it seems obvious to me that the imitation game has lost its relevance, and we need something new."
  },
  {
    "objectID": "2023_nightingale/index.html#we-need-to-talk-about-overconfidence",
    "href": "2023_nightingale/index.html#we-need-to-talk-about-overconfidence",
    "title": "AI in the time of chatGPT",
    "section": "We need to talk about (over)confidence",
    "text": "We need to talk about (over)confidence\n\nWhat is overconfidence?\n \nAn overconfident classifier thinks it’s better at separating classes than it actually is.\nHence we need to make predicted probabilities less extreme by pushing them toward the centre. \n\n\nWhy does it matter?\nOptimal decisions can only be made with calibrated probabilities. - Example: If we trained on balanced classes but want to deploy with 4 times as many positives compared to negatives, we lower the decision threshold to 0.2.  - With a poor probability estimator such as naive Bayes, decision thresholds have to be learned. \n\n\nWhat to do about overconfidence\n \nShameless plug \n\n\nComputer says ‘I Don’t Know’\n \nBackground Check: A general technique to build more reliable and versatile classifiers (ICDM 2016)"
  },
  {
    "objectID": "2023_nightingale/index.html#ai-in-the-time-of-chatgpt-1",
    "href": "2023_nightingale/index.html#ai-in-the-time-of-chatgpt-1",
    "title": "AI in the time of chatGPT",
    "section": "AI in the time of ChatGPT",
    "text": "AI in the time of ChatGPT\n\nThe distinction between learning and reasoning is much less clearcut once you train on language data.\nIt is to be expected that other task layers on top of LLMs will give rise to many other capabilities.\nHow such capabilities can be assessed and measured is a wide-open question, see e.g. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models.\nProperly quantifying confidence and imbuing AI with the capability to say ‘I don’t know’ is key for trustworthiness.\n\n\nAcknowledgements\nMany thanks to collaborators Yu Chen, Tom Diethe, Jose Hernandez-Orallo, Meelis Kull, Miquel Perello-Nieto, Ricardo Prudencio, Raul Santos-Rodriguez, Telmo Silva Filho, Kacper Sokol, Hao Song, and many others."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About\nThis website contains a set of slides."
  },
  {
    "objectID": "2020_turing/MD/Measurement.html",
    "href": "2020_turing/MD/Measurement.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\nConcatenate then measure gives the same result as measure then calculate.\n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform, as in cross-validation).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance (or made uniform, as in stratified cross-validation).\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2020_turing/MD/Measurement.html#towards-measurement-theory-for-ml",
    "href": "2020_turing/MD/Measurement.html#towards-measurement-theory-for-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "M1\n\n\nConcatenate then measure gives the same result as measure then calculate.\n\n\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Predicted}\\ + & \\text{Predicted}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & TP_i            & FN_i            & Pos_i \\\\\\\\\n\\text{Actual}\\ - & FP_i            & TN_i            & Neg_i \\\\\\\\\n           & PPos_i          & PNeg_i          & N_i  \\\\\\\\ \\hline\n\\end{array}\n\\]\nAssume we have two of these, \\(C_1\\) and \\(C_2\\) (e.g. as obtained in two-fold cross-validation) and their cell-wise sum \\(C_1 \\circ C_2\\).\n\n\n\n\\[\n\\begin{align}\nacc(C_i) &= \\frac{TP_i+TN_i}{N_i}, i=1,2 \\\\\\\\\nacc(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i+\\sum_i TN_i}{\\sum_i N_i} \\\\\\\\\n&= \\frac{N_1}{N}acc(C_1) + \\frac{N_2}{N}acc(C_2)\n\\end{align}\n\\]\nThis is a weighted average where the weights do not depend on the performance of the two models (and can be made uniform, as in cross-validation).\n\n\n\n\\[\n\\begin{align}\ntpr(C_i) &= \\frac{TP_i}{Pos_i}, i=1,2 \\\\\\\\\ntpr(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i Pos_i} \\\\\\\\\n&= \\frac{Pos_1}{Pos}tpr(C_1) + \\frac{Pos_2}{Pos}tpr(C_2)\n\\end{align}\n\\]\nAgain, a weighted average with weights that can be determined in advance (or made uniform, as in stratified cross-validation).\n\n\n\n\\[\n\\begin{align}\nprec(C_i) &= \\frac{TP_i}{PPos_i}, i=1,2 \\\\\\\\\nprec(C_1 \\circ C_2) &= \\frac{\\sum_i TP_i}{\\sum_i PPos_i} \\\\\\\\\n&= \\frac{PPos_1}{PPos}prec(C_1) + \\frac{PPos_2}{PPos}prec(C_2)\n\\end{align}\n\\]\nNow, the weights are themselves measurements, without which the concatenated value cannot be calculated from the component values.\n\n\n\n\\[\n\\begin{align}\nFscore(C_1 \\circ C_2) &= \\frac{Pos_1+PPos_1}{Pos+PPos}Fscore(C_1) \\nonumber \\\\\\\\ &+ \\frac{Pos_2+PPos_2}{Pos+PPos}Fscore(C_2)\n\\end{align}\n\\]\n\nFlach, P., 2019. Performance Evaluation in Machine Learning: The Good, The Bad, The Ugly and The Way Forward. In 33rd AAAI Conference on Artificial Intelligence."
  },
  {
    "objectID": "2020_turing/MD/Dimensions.html",
    "href": "2020_turing/MD/Dimensions.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Physical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added, quantities need to be commensurable (have the same dimension).\n\nNB. This gives priority to additive scales!\n\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose \\(L_x\\), \\(L_y\\), \\(L_z\\) as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2020_turing/MD/Dimensions.html#units-dimensions-and-types",
    "href": "2020_turing/MD/Dimensions.html#units-dimensions-and-types",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Physical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added, quantities need to be commensurable (have the same dimension).\n\nNB. This gives priority to additive scales!\n\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\n\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\n\n\nAngle is a ratio of lengths, hence dimensionless; but it has a unit (radians, degrees). This leads to angular velocity having dimension \\(T^{-1}\\), which is odd.\n\ncould choose \\(L_x\\), \\(L_y\\), \\(L_z\\) as distinct dimensions.\n\nFunctions such as \\(\\exp\\), \\(\\sin\\) etc. can only take and result in dimensionless quantities.\n\ne.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is an arbitrary unit of volume.\n\n\n\n\n\n\nrelative frequencies, probabilities, evaluation metrics…\nStill, we treat derived quantities such as \\(\\log p\\) as having a unit (bits, log-likelihood).\nWe also have different concatenation operators, such as \\(p_1+p_2\\) for the union of mutually exclusive events, \\(p_1 \\cdot p_2\\) for the joint probability of independent events."
  },
  {
    "objectID": "2020_turing/MD/Scales.html",
    "href": "2020_turing/MD/Scales.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\\[F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\]\n\\[1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\] \n\n\n\n\nLinearise: e.g., \\[prec=TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP\\]\nMap \\([1,1/\\pi]\\) back to \\([0,1]\\): e.g., \\[precG = \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP\\] \n\n\n\n\n   \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2020_turing/MD/Scales.html#change-of-scale-examples-in-ml",
    "href": "2020_turing/MD/Scales.html#change-of-scale-examples-in-ml",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Linear interpolation: is it justified?\nArithmetic averaging: is it justified?\nThis is where scale really matters.\n\n\nAka accuracy over a modified confusion matrix:\n\\[\n\\begin{array}{lccc}\n\\hline\n           & \\text{Pred}\\ + & \\text{Pred}\\ - &     \\\\\\\\ \\hline\n\\text{Actual}\\ + & {\\color{red}{\\beta^2}} TP            & {\\color{red}{\\beta^2}} FN            & {\\color{red}{\\beta^2}} Pos \\\\\\\\\n\\text{Actual}\\ - & FP            & {\\color{red}{TP}}            & Neg{\\color{red}{-TN+TP}} \\\\\\\\\n           & \\ldots          & \\ldots          & \\ldots  \\\\\\\\ \\hline\n\\end{array}\n\\]\n\\[F_{\\beta} = \\frac{(\\beta^2+1) TP}{(\\beta^2+1) TP + \\beta^2 FN + FP}\\]\n\\[1/F_{\\beta} = \\frac{\\beta^2}{\\beta^2+1} 1/rec + \\frac{1}{\\beta^2+1} 1/prec\\] \n\n\n\n\nLinearise: e.g., \\[prec=TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP\\]\nMap \\([1,1/\\pi]\\) back to \\([0,1]\\): e.g., \\[precG = \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP\\] \n\n\n\n\n   \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\n\n\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. In Advances in neural information processing systems (pp. 838-846)."
  },
  {
    "objectID": "2020_turing/MD/Scales.html#squared-loss-and-log-loss",
    "href": "2020_turing/MD/Scales.html#squared-loss-and-log-loss",
    "title": "Peter Flach Slides",
    "section": "Squared loss and Log-loss",
    "text": "Squared loss and Log-loss\n\nThese are most commonly used to evaluate probability estimates against ‘ideal’ probabilities 0 and 1.\nAlternatively, they can be interpreted as expected misclassification loss, aggregating over all possible skews (class prevalence or cost proportion).\nFrom the latter perspective they differ only in the scale on which skews are measured.\n\n\nCost-sensitive classification\n\nLoss at a particular operating point:\n\n\\[Q(t; \\pi , c_0, c_1) =  c_0 \\pi (1 -F_0(t)) + c_1 (1-\\pi) F_1(t)\\]\n\nRe-parametrising on an arithmetic scale:\n\n\\[Q(t; \\pi , b, c) =  b\\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right]\\]\n\nAssuming \\(b, c\\) independent:\n\n\\[L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right] dc \\]\n\n\nDeriving squared loss\n\\[L = \\mathbb{E}[b]\\int_0 ^1 \\left[c \\pi (1 -F_0(t)) + (1-c) (1-\\pi) F_1(t)\\right] dc \\]\n\nAssuming a calibrated probabilistic classifier, then \\(t=c\\) is optimal; with a budget \\(\\mathbb{E}[b]=2\\):\n\n\\[ L = \\pi \\int_0^1 s^{2} f_0(s) ds + (1-\\pi) \\int_0^1 (1-s)^{2} f_1(s) ds \\]\n\nThis is squared loss, also known as the Brier score. \n\n\n\nChanging the cost scale\n\nThe starting point is the same:\n\n\\[Q(t; \\pi , c_0, c_1) =  c_0 \\pi (1 -F_0(t)) + c_1 (1-\\pi) F_1(t)\\]\n\nRe-parametrising on a harmonic scale:\n\n\\[Q(t; \\pi , d, c) =  d\\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right]\\]\n\nAssuming \\(d, c\\) independent:\n\n\\[L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right] dc \\]\n\n\nDeriving log-loss\n\\[L = \\mathbb{E}[d]\\int_0 ^1 \\left[\\frac{1}{1-c} \\pi (1 -F_0(t)) + \\frac{1}{c} (1-\\pi) F_1(t)\\right] dc \\]\n\nAssuming a calibrated probabilistic classifier and a budget \\(\\mathbb{E}[d]=1/2\\):\n\n\\[ L = \\pi/2 \\int_0^1 -\\ln (1-s) f_0(s) ds + (1-\\pi)/2 \\int_0^1 -\\ln s f_1(s) ds \\]\n\nThis is log-loss. \n\n\n\nIllustration\n\nCalibration: poor (left), perfect (right).\nCost scale: arithmetic (blue), harmonic (red).\n\n   \nLog-loss emphasises extreme values of \\(c\\). \n\n\nSampled cost parameters\n   \nLeft: arithmetic; right: harmonic.\n\n\nMore here\nFlach, P., 2015. Cost-Sensitive Classification Meets Proper Scoring Rules. Second international workshop on learning over multiple contexts (LMCE’15) at ECML-PKDD 2015."
  },
  {
    "objectID": "2020_turing/MD/Intro.html",
    "href": "2020_turing/MD/Intro.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Transparent machine learning requires knowledge of - how a model was built; - how a model makes decisions; - how well it can be expected to perform; - what its operating assumptions and limitations are.\n\n\n\nNeed to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nOperating points & contexts can change.\n\n   \n\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research 13(Oct), pp.2813-2869.\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery 33, pp.805-847.\n\n\n\n\n\n\nQuantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2020_turing/MD/Intro.html#transparency",
    "href": "2020_turing/MD/Intro.html#transparency",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Transparent machine learning requires knowledge of - how a model was built; - how a model makes decisions; - how well it can be expected to perform; - what its operating assumptions and limitations are.\n\n\n\nNeed to consider multiple measures.\n\ne.g. true & false positive rate, precision & recall\n\nOperating points & contexts can change.\n\n   \n\n\n\n\nAccuracy assumes equal misclassification costs;\nF-score additionally assumes that true negatives don’t add value;\nboth assume a fixed operating point and class distribution;\nAUC aggregates over operating points and class distributions in a specific way.\n\n\n\n\nHernandez-Orallo, J., Flach, P. and Ferri, C., 2012. A unified view of performance metrics: translating threshold choice into expected classification loss. Journal of Machine Learning Research 13(Oct), pp.2813-2869.\nFerri, C., Hernandez-Orallo, J. and Flach, P., 2019. Setting decision thresholds when operating conditions are uncertain. Data Mining and Knowledge Discovery 33, pp.805-847.\n\n\n\n\n\n\nQuantifying performance requires careful consideration of measurement scales. Are there ML equivalents of physical units?\nWhat we can observe is rarely of direct interest. The most important performance indicators are latent!\nUltimately empirical ML needs to make causal (or counterfactual) statements:\n\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced."
  },
  {
    "objectID": "2020_turing/MD/Latent.html",
    "href": "2020_turing/MD/Latent.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2020_turing/MD/Latent.html#latent-variable-models",
    "href": "2020_turing/MD/Latent.html#latent-variable-models",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Psychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\n\n \n\\(E[x_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\exp(-a_j(\\theta_i-\\delta_j))}\\)\n\n\n\n \n\\(E[p_{ij}|\\delta_j,a_j] = \\frac{1}{1+\\left(\\frac{\\delta_i}{\\theta_j}\\cdot\\frac{1-\\theta_j}{1-\\delta_i} \\right)^{a_j}}\\)\n\n\n\n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2020_turing/MD/Outlook.html",
    "href": "2020_turing/MD/Outlook.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\n\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2020_turing/MD/Outlook.html#outlook",
    "href": "2020_turing/MD/Outlook.html#outlook",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Proper treatment of performance evaluation in machine learning (and AI more generally) requires a sophisticated model with the following components: - Measurement theory for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\n\nPart of this work was funded through a project with the Alan Turing Institute.\nMany thanks to Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Telmo Filho, Hao Song and many others."
  },
  {
    "objectID": "2020_turing/MD/Prelims.html",
    "href": "2020_turing/MD/Prelims.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Segment 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\) Segment 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\) Overall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\)\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = A(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = H(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(A(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTop (sensitive to small values) to bottom (sensitive to large values): harmonic, geometric, arithmetic, quadratic.\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: fixed zero, ratios are also meaningful\nTransformed scales: e.g. log-ratio\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nScores in an ensemble are often arithmetically averaged to obtain an overall score.\nBut what if the base classifiers are probability estimators? Do you \n\nContinue to use arithmetic mean? \nConvert to bits first (aka log-likelihoods)? \nUse geometric mean?"
  },
  {
    "objectID": "2020_turing/MD/Prelims.html#means-and-scales",
    "href": "2020_turing/MD/Prelims.html#means-and-scales",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Segment 1: distance \\(d_1\\), time \\(t_1\\), velocity \\(v_1=d_1/t_1\\) Segment 2: distance \\(d_2\\), time \\(t_2\\), velocity \\(v_2=d_2/t_2\\) Overall: distance \\(d=d_1+d_2\\), time \\(t=t_1+t_2\\), velocity \\(v=(d_1+d_2)/(t_1+t_2)\\)\n\n\\(t_1=t_2 \\Rightarrow v = (v_1+v_2)/2 = A(v_1,v_2)\\) \n\nor in general: \\(v = {\\color{red}{(t_1/t)}}\\cdot v_1 + {\\color{red}{(t_2/t)}}\\cdot v_2\\) \n\n\\(d_1=d_2 \\Rightarrow v = 2/(1/v_1+1/v_2) = H(v_1,v_2)\\) \n\nor in general: \\(1/v = {\\color{red}{(d_1/d)}}\\cdot 1/v_1 + {\\color{red}{(d_2/d)}}\\cdot 1/v_2\\) \n\n\n\n\nMost means \\(M(x,y)\\) are quasi-arithmetic: there exists a change of scale \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) such that \\(M(x,y) = g^{-1}(A(g(x),g(y)))\\).\n\n\n\nMean\n\\(M(x,y)\\)\n\\(g(x)\\)\n\n\n\n\nArithmetic\n\\((x+y)/2\\)\n\\(x\\)\n\n\nHarmonic\n\\(2/(1/x+1/y)\\)\n\\(1/x\\)\n\n\nGeometric\n\\(\\sqrt{xy}\\)\n\\(\\ln x\\)\n\n\nQuadratic\n\\(\\sqrt{(x^2+y^2)/2}\\)\n\\(x^2\\)\n\n\nGeneralised\n\\(\\sqrt[p]{(x^p+y^p)/2}\\)\n\\(x^p\\)\n\n\n\n\n\n\n \nTop (sensitive to small values) to bottom (sensitive to large values): harmonic, geometric, arithmetic, quadratic.\n\n\n\n   \n\n\n\n\nNominal: no order, no scale\nOrdinal: order, no scale\nInterval: differences are meaningful, but no zero\nRatio: fixed zero, ratios are also meaningful\nTransformed scales: e.g. log-ratio\n\nThere should be more? E.g. scales bounded from both sides. \n\n\n\n\nScores in an ensemble are often arithmetically averaged to obtain an overall score.\nBut what if the base classifiers are probability estimators? Do you \n\nContinue to use arithmetic mean? \nConvert to bits first (aka log-likelihoods)? \nUse geometric mean?"
  },
  {
    "objectID": "2021_jgi/MD/All.html",
    "href": "2021_jgi/MD/All.html",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed on each part, which is (a) very unlikely, and (b) not under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for a given trade-off between precision and recall.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2021_jgi/MD/All.html#why-should-you-care-about-measurement",
    "href": "2021_jgi/MD/All.html#why-should-you-care-about-measurement",
    "title": "Peter Flach Slides",
    "section": "",
    "text": "Measurements are relevant in data science and AI for at least two reasons: - Features often are measurements on some scale, which dictates admissible statistics and operations. - E.g., taking the expectation assumes a linear scale. - Performance metrics are also measurements, and hence the same applies.\nThis project looked at foundational issues, of which there are many!\n\n\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean.\n\n\n\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed on each part, which is (a) very unlikely, and (b) not under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision. \n\n\n\n\n\n\nfrom ROC via PR to PRG\n\n\nFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015.\n\n\n\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\] \n\n\n\n\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for a given trade-off between precision and recall.\n\n\n\n\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2021_jgi/MD/All.html#scales-units-dimensions-and-types",
    "href": "2021_jgi/MD/All.html#scales-units-dimensions-and-types",
    "title": "Peter Flach Slides",
    "section": "Scales, units, dimensions and types",
    "text": "Scales, units, dimensions and types\nPerhaps surprisingly, there doesn’t seem to be a definitive framework to link all these concepts together.\nWe’ll look at it from a few perspectives:\n\nLevels of measurement\nThe physics perspective\nThe computer science perspective"
  },
  {
    "objectID": "2021_jgi/MD/All.html#levels-of-measurement",
    "href": "2021_jgi/MD/All.html#levels-of-measurement",
    "title": "Peter Flach Slides",
    "section": "Levels of measurement",
    "text": "Levels of measurement\n   \nEarly proposal from a psychologist (Stevens, 1946), still influential although somewhat rigid and limited.\n\nStevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”.\n\n\nAdmissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above.\n\n\nLevels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning! \n\n\nAlternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2021_jgi/MD/All.html#the-physics-perspective",
    "href": "2021_jgi/MD/All.html#the-physics-perspective",
    "title": "Peter Flach Slides",
    "section": "The physics perspective",
    "text": "The physics perspective\n\nPhysical quantities have an associated dimension (Fourier, 1822).\nIn order to be compared and added or subtracted, quantities need to be commensurable (have the same dimension).\nIncommensurable quantities may be multiplied and divided, giving new derived dimensions.\n\nE.g. pressure has dimension \\(M L^{-1} T^{-2}\\)\nSI units Pascal = Newton/m\\(^2\\) = kg/(m*s\\(^2\\)).\n\n\n\nDimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\).\n\n\n\n\nHow to build on this in data science and AI?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…"
  },
  {
    "objectID": "2021_jgi/MD/All.html#the-computer-science-perspective",
    "href": "2021_jgi/MD/All.html#the-computer-science-perspective",
    "title": "Peter Flach Slides",
    "section": "The computer science perspective",
    "text": "The computer science perspective\n\nAbstract data types are more flexible than dimensions or scale types as they can be adapted to the situation of interest.\n\nprovide relevant meta-data about measurements\nlink to useful operations.\n\nIn particular, higher-order functional languages such as Haskell allow reasoning with and about types.\n\nThis provides a formal language and logic for measurement meta-data.\n\nThe challenge is to develop a generally agreed “Systeme international” of ML measurements.\n\n\nExample: Shannon entropy\n \n\n\nExample: Scoring rules"
  },
  {
    "objectID": "2021_jgi/MD/All.html#you-cant-always-measure-what-you-want",
    "href": "2021_jgi/MD/All.html#you-cant-always-measure-what-you-want",
    "title": "Peter Flach Slides",
    "section": "You can’t always measure what you want…",
    "text": "You can’t always measure what you want…\n\nPsychologists have long understood that people’s abilities (and the difficulty of a task) are not directly observable and need to be estimated.\n\nItem-response theory, factor analysis\n\nWe can adapt those latent variable models to machine learning, to estimate ability of classifiers as well as difficulty of instances and datasets.\n\n\nIRT from a machine learning perspective\n\n\n\nIRT\n\n\n\n\\(\\theta_i\\): ability of participant \\(i\\)\n\\(\\delta_j\\), \\(a_j\\): difficulty & discrimination of item \\(j\\)\n\\(x_{ij}\\): binary response (correct/incorrect)\n\n\n\nBeta-IRT\n\n\n\nBeta-IRT\n\n\n\ncontinuous responses \\(p_{ij}\\)\nabilities & difficulties \\(\\in [0,1]\\)\n\n\n\nBeta-IRT: flexible Item Characteristic Curves\n\n\n\nBeta-IRT ICC\n\n\n\ndiscrimination \\(a_j\\) can be negative, indicating an item that confuses high-ability participants! \n\n\n\nIdea 1: Identifying noisy examples\n \n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019.\n\n\n\nIdea 2: Adaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved.\n\n\n\nCAT results\n \n\nSong, H. and Flach, P., 2020. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Int J Interactive Multimedia and AI 2021."
  },
  {
    "objectID": "2021_jgi/MD/All.html#outlook",
    "href": "2021_jgi/MD/All.html#outlook",
    "title": "Peter Flach Slides",
    "section": "Outlook",
    "text": "Outlook\nUltimately, empirical ML needs to make causal statements:\n\nAlgorithm A outperformed algorithm B because the classes were highly imbalanced.\n\n\nI.e., if the classes were re-balanced (counterfactual intervention) the difference in performance would disappear. \n\nNB. In empirical ML we can actually carry out interventions, which makes causal inference a whole lot easier!"
  },
  {
    "objectID": "2021_jgi/MD/All.html#conclusions",
    "href": "2021_jgi/MD/All.html#conclusions",
    "title": "Peter Flach Slides",
    "section": "Conclusions",
    "text": "Conclusions\nProper treatment of performance evaluation in data science and AI requires a sophisticated measurement framework with the following components: - Coherent types and meta-data for the observable performance indicators; - Latent-variable models for the unobservable performance indicators of interest; - Causal models to allow for counterfactual reasoning.\n\nAcknowledgements\nPart of this work was funded through a project with the Alan Turing Institute; papers, code and videos can be accessed here.\nMany thanks to Hao Song, the Research Associate on the project; and collaborators Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Raul Santos-Rodriguez and many others."
  },
  {
    "objectID": "2022_monash/index.html#performance-measurement-is-easy",
    "href": "2022_monash/index.html#performance-measurement-is-easy",
    "title": "The highs and lows of performance evaluation",
    "section": "Performance measurement is easy…",
    "text": "Performance measurement is easy…\nIf I split a data set in two or more parts, is a classifier’s accuracy on the entire data set equal to the average* of the accuracies on the separate parts?\nYes – provided the parts are of equal size (e.g., cross-validation). \nWhat about per-class recall ( = true positive rate)? \nYes – provided the parts have the same class distribution (e.g., stratified CV). \n*To be precise: the arithmetic mean."
  },
  {
    "objectID": "2022_monash/index.html#or-is-it",
    "href": "2022_monash/index.html#or-is-it",
    "title": "The highs and lows of performance evaluation",
    "section": "…or is it?",
    "text": "…or is it?\nIs a classifier’s precision on the entire data set equal to the average of the precisions on the parts?\nIT IS NOT! \nUnless the classifier’s predictions are equally distributed over the classes on each part, which is neither likely nor under the experimenter’s control. \nThe same applies a fortiori to F-score, which aggregates recall and precision."
  },
  {
    "objectID": "2022_monash/index.html#an-early-result-precision-recall-gain-curves",
    "href": "2022_monash/index.html#an-early-result-precision-recall-gain-curves",
    "title": "The highs and lows of performance evaluation",
    "section": "An early result: Precision-Recall-Gain curves",
    "text": "An early result: Precision-Recall-Gain curves\n\nfrom ROC via PR to PRGFlach, P. and Kull, M., 2015. Precision-recall-gain curves: PR analysis done right. NIPS 2015."
  },
  {
    "objectID": "2022_monash/index.html#how-we-fixed-it-change-of-scale",
    "href": "2022_monash/index.html#how-we-fixed-it-change-of-scale",
    "title": "The highs and lows of performance evaluation",
    "section": "How we fixed it: change of scale",
    "text": "How we fixed it: change of scale\n\nTake reciprocals: \\[\n\\begin{align}\nprec &= TP/(TP+FP) \\rightarrow 1/prec = 1+FP/TP \\\\\\\\\nrec  &= TP/(TP+FN) \\rightarrow 1/rec  = 1+FN/TP \\\\\\\\\n\\\\ \\\\\\\\\n\\end{align}\n\\]\nClip \\([1,\\infty]\\) to \\([1,1/\\pi]\\) to exlude overly small values of precision/recall. \\[\n\\begin{align}\n\\\\ \\\\\\\\\n\\end{align}\n\\] \nMap \\([1,1/\\pi]\\) back to unit interval: \\[\n\\begin{align}\nprecG &= \\frac{prec-\\pi}{(1-\\pi)prec} = 1 - \\frac{\\pi}{1-\\pi} FP/TP \\\\\\\\\nrecG  &= \\frac{rec-\\pi}{(1-\\pi)rec} = 1 - \\frac{\\pi}{1-\\pi} FN/TP \\\\\\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "2022_monash/index.html#et-voila",
    "href": "2022_monash/index.html#et-voila",
    "title": "The highs and lows of performance evaluation",
    "section": "Et voila!",
    "text": "Et voila!\n   \n\narea under PRG curve \\(\\propto\\) expected \\(F_1\\) score;\nconvex hull can be used to determine the optimal operating point for given precision-recall trade-off."
  },
  {
    "objectID": "2022_monash/index.html#what-i-will-talk-about",
    "href": "2022_monash/index.html#what-i-will-talk-about",
    "title": "The highs and lows of performance evaluation",
    "section": "What I will talk about",
    "text": "What I will talk about\n\nScales, units, dimensions and types\n\nPerspectives from psychology, physics and computer science\n\nYou can’t always measure what you want\n\nLatent variable models\n\nConclusions and outlook"
  },
  {
    "objectID": "2022_monash/index.html#stevens-typology",
    "href": "2022_monash/index.html#stevens-typology",
    "title": "The highs and lows of performance evaluation",
    "section": "Stevens’ typology",
    "text": "Stevens’ typology\n\n\n\nScale type\nDescription\nTransformations\n\n\n\n\nNominal\nno order, no unit\npermutation\n\n\nOrdinal\norder, no unit\nmonotone\n\n\nInterval\ncan choose unit and zero\naffine\n\n\nRatio\nfixed zero, can choose unit\nlinear\n\n\n\nThe appropriate scale type is determined by the transformation furthest down the list which is still “meaningful”."
  },
  {
    "objectID": "2022_monash/index.html#admissible-statistics",
    "href": "2022_monash/index.html#admissible-statistics",
    "title": "The highs and lows of performance evaluation",
    "section": "Admissible statistics",
    "text": "Admissible statistics\n\n\n\nScale type\nStatistics\n\n\n\n\n\nNominal\nmode\n\n\n\nOrdinal\nmedian, quantile, range\n\n\n\nInterval\narithmetic mean, variance\n\n\n\nRatio\ngeometric mean, coefficient of variation\n\n\n\n\nEach scale type inherits statistics from levels above."
  },
  {
    "objectID": "2022_monash/index.html#levels-of-measurement-discussion",
    "href": "2022_monash/index.html#levels-of-measurement-discussion",
    "title": "The highs and lows of performance evaluation",
    "section": "Levels of measurement: discussion",
    "text": "Levels of measurement: discussion\n\nMany statisticians challenge the rigid connection between scale types and admissible statistics.\n\n\nE.g., Spearman’s rank correlation statistic would not be admissible for ordinal data.\n\n\nMany common scales do not fit well:\n\n\nscales bounded from both sides;\nscales with a fixed unit;\ninteger measurements.\n\nSuch scales abound in machine learning!"
  },
  {
    "objectID": "2022_monash/index.html#alternative-typologies",
    "href": "2022_monash/index.html#alternative-typologies",
    "title": "The highs and lows of performance evaluation",
    "section": "Alternative typologies",
    "text": "Alternative typologies\nMosteller and Tukey (1977): Names, Grades (e.g., beginner, intermediate, advanced), Ranks (1, 2, …), Counted fractions (e.g., percentages), Counts (non-negative integers), Amounts (non-negative real numbers), Balances (unbounded, positive or negative values).\nChrisman (1998): Nominal, Graded membership (e.g., fuzzy sets), Ordinal, Interval, Log-interval, Extensive ratio, Cyclical ratio (e.g., angles or time of day) Derived ratio, Counts, Absolute (e.g., probabilities)."
  },
  {
    "objectID": "2022_monash/index.html#dimensional-analysis-discussion",
    "href": "2022_monash/index.html#dimensional-analysis-discussion",
    "title": "The highs and lows of performance evaluation",
    "section": "Dimensional analysis: discussion",
    "text": "Dimensional analysis: discussion\n\nDimensions can cancel, leading to dimensionless quantities.\n\nE.g., angle is a ratio of lengths, hence dimensionless; but it has units (radians, degrees).\nSometimes units also cancel, e.g. ABV has unit ml ethanol per 100 ml liquid (percentage).\n\nTranscendental functions (\\(\\exp\\), \\(\\sin\\) etc.) require dimensionless and unitless quantities.\n\nE.g., \\(\\log V\\) where \\(V\\) has dimension \\(L^3\\) should be thought of as \\(\\log (V/v)\\) where \\(v\\) is the unit of \\(V\\)."
  },
  {
    "objectID": "2022_monash/index.html#how-to-build-on-this-in-data-science-and-ai",
    "href": "2022_monash/index.html#how-to-build-on-this-in-data-science-and-ai",
    "title": "The highs and lows of performance evaluation",
    "section": "How to build on this in data science and AI?",
    "text": "How to build on this in data science and AI?\n\nBoth perspectives (levels of measurement and dimensional analysis) have interesting features but appear overly focused on establishing a ‘true’ scale type or dimension for a measurement.\n\nMachine learning needs something more flexible.\nIn particular, a better treatment of “dimensionless” quantities which are everywhere you look!\n\nrelative frequencies, probabilities, evaluation metrics…"
  },
  {
    "objectID": "2022_monash/index.html#example-shannon-entropy",
    "href": "2022_monash/index.html#example-shannon-entropy",
    "title": "The highs and lows of performance evaluation",
    "section": "Example: Shannon entropy",
    "text": "Example: Shannon entropy"
  },
  {
    "objectID": "2022_monash/index.html#example-scoring-rules",
    "href": "2022_monash/index.html#example-scoring-rules",
    "title": "The highs and lows of performance evaluation",
    "section": "Example: Scoring rules",
    "text": "Example: Scoring rules"
  },
  {
    "objectID": "2022_monash/index.html#irt-from-a-machine-learning-perspective",
    "href": "2022_monash/index.html#irt-from-a-machine-learning-perspective",
    "title": "The highs and lows of performance evaluation",
    "section": "IRT from a machine learning perspective",
    "text": "IRT from a machine learning perspective\n \n\n\\(\\theta_i\\): ability of participant \\(i\\)\n\\(\\delta_j\\), \\(a_j\\): difficulty & discrimination of item \\(j\\)\n\\(x_{ij}\\): binary response (correct/incorrect)"
  },
  {
    "objectID": "2022_monash/index.html#beta-irt",
    "href": "2022_monash/index.html#beta-irt",
    "title": "The highs and lows of performance evaluation",
    "section": "Beta-IRT",
    "text": "Beta-IRT\n \n\ncontinuous responses \\(p_{ij}\\)\nabilities & difficulties \\(\\in [0,1]\\)"
  },
  {
    "objectID": "2022_monash/index.html#beta-irt-flexible-item-characteristic-curves",
    "href": "2022_monash/index.html#beta-irt-flexible-item-characteristic-curves",
    "title": "The highs and lows of performance evaluation",
    "section": "Beta-IRT: flexible Item Characteristic Curves",
    "text": "Beta-IRT: flexible Item Characteristic Curves\n \n\ndiscrimination \\(a_j\\) can be negative, indicating an item that confuses high-ability participants!"
  },
  {
    "objectID": "2022_monash/index.html#idea-1-identifying-noisy-examples",
    "href": "2022_monash/index.html#idea-1-identifying-noisy-examples",
    "title": "The highs and lows of performance evaluation",
    "section": "Idea 1: Identifying noisy examples",
    "text": "Idea 1: Identifying noisy examples\n \n\nChen, Y., Prudencio, R.B., Diethe, T. and Flach, P., 2019. \\(\\beta^3\\)-IRT: A New Item Response Model and its Applications. AISTATS 2019."
  },
  {
    "objectID": "2022_monash/index.html#idea-2-adaptive-testing",
    "href": "2022_monash/index.html#idea-2-adaptive-testing",
    "title": "The highs and lows of performance evaluation",
    "section": "Idea 2: Adaptive testing",
    "text": "Idea 2: Adaptive testing\nUse a trained IRT model to evaluate a new classifier on a small number of datasets.\n\nStart with initial guess of classifier ability.\nChoose next dataset using an item selection criterion.\nEvaluate classifier and update ability estimation.\nRepeat until stopping criterion is achieved."
  },
  {
    "objectID": "2022_monash/index.html#cat-results",
    "href": "2022_monash/index.html#cat-results",
    "title": "The highs and lows of performance evaluation",
    "section": "CAT results",
    "text": "CAT results\n \n\nSong, H. and Flach, P., 2020. Efficient and Robust Model Benchmarks with Item Response Theory and Adaptive Testing. Int J Interactive Multimedia and AI 2021."
  },
  {
    "objectID": "2022_monash/index.html#acknowledgements",
    "href": "2022_monash/index.html#acknowledgements",
    "title": "The highs and lows of performance evaluation",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nPart of this work was funded through a project with the Alan Turing Institute; papers, code and videos can be accessed here.\nMany thanks to Hao Song, the Research Associate on the project; and collaborators Jose Hernandez-Orallo, Kacper Sokol, Meelis Kull, Tom Diethe, Yu Chen, Ricardo Prudencio, Telmo Filho, Miquel Perello-Nieto, Raul Santos-Rodriguez and many others."
  }
]